[{"index": "539087dd20f70186a0d62837", "title": "Fast perspective volume rendering with splatting by utilizing a ray-driven approach", "abstract": "", "year": "1996", "venue": "Proceedings of the 7th conference on Visualization '96", "citations": ["5390979920f70186a0e0052d", "53909e7c20f70186a0e2bbd6", "5390b86b20f70186a0f2814e", "539087e620f70186a0d67561", "539087eb20f70186a0d6c0c0", "539087f820f70186a0d72a72", "5390880720f70186a0d79c1e", "539089ab20f70186a0d96a88", "539089bb20f70186a0d98870", "539089bb20f70186a0d98858", "539089bb20f70186a0d9884d", "539089bb20f70186a0d988cb", "53908b2a20f70186a0db8716", "53908b6c20f70186a0dbd34c", "53908bcc20f70186a0dc5719"], "references": ["539087a120f70186a0d4748f", "539087a120f70186a0d47499", "539087ae20f70186a0d4cd20", "539087be20f70186a0d51ef0", "539087cb20f70186a0d59e80", "539087cf20f70186a0d5caa8", "5390878720f70186a0d36057", "5390879220f70186a0d3d937", "5390879920f70186a0d41b8b", "5390879920f70186a0d4203f", "539087fe20f70186a0d74a0a", "5390881220f70186a0d7ec95", "53908b6c20f70186a0dbf4a1", "53908bad20f70186a0dc3156", "53908bcc20f70186a0dc6cc4", "5390958a20f70186a0def783", "5390958a20f70186a0def76a"], "authors": ["Klaus Mueller", "Roni Yagel"], "_id": {"$oid": "5797a6e2c60b4bee2ddcbb22"}}, {"index": "539087d920f70186a0d6092d", "title": "Classification and local error estimation of interpolation and derivative filters for volume rendering", "abstract": "", "year": "1996", "venue": "Proceedings of the 1996 symposium on Volume visualization", "citations": ["5390afc920f70186a0ed26c5", "539087e620f70186a0d67561", "5390880720f70186a0d79c24", "539089bb20f70186a0d9883c", "53908b0220f70186a0db1912"], "references": ["539087be20f70186a0d51e83", "539087c720f70186a0d56c26", "5390877f20f70186a0d30621", "5390878720f70186a0d36057", "5390879220f70186a0d3d25d", "5390881220f70186a0d7ecbb", "5390881220f70186a0d7ec9d", "5390882120f70186a0d85347", "539088b820f70186a0d905eb", "539089bb20f70186a0d9882d", "5390958a20f70186a0defa93"], "authors": ["Torsten M\u00f6ller", "Raghu Machiraju", "Klaus Mueller", "Roni Yagel"], "_id": {"$oid": "5797a7b3c60b4bee2de66c95"}}, {"index": "5390b5fa20f70186a0f10c40", "title": "Flexible two IC chipset for DVB on cable reception", "abstract": "A DVB compliant chipset for QAM reception on cable was developed. It consists of two ICs, a down converter and an integrated QAM processor/FEC device including ADC, digital demodulation, equalization, clock and carrier recovery, and a forward error correction", "year": "1996", "venue": "IEEE Transactions on Consumer Electronics", "citations": [], "references": [], "authors": ["M. Haas", "F. Kuttner", "T. Kodytek", "H. Kriedt", "E. Krug", "S. Meier", "K. Mueller", "C. v. Reventlow", "R. Schmidmaier", "M. Schoebinger", "G. Sebald", "P. Solanti", "M. Tiebout"], "_id": {"$oid": "5797a8a9c60b4bee2df286fe"}}, {"index": "5390b5fa20f70186a0f10c41", "title": "Advanced two IC chipset for DVB on satellite reception", "abstract": "A QPSK chipset applicable for digital video broadcast (DVB) signals from a satellite is described. It consists of two ICs, a bipolar I/Q demodulator with an on-chip AGC and delayed tuner AGC and a CMOS QPSK processor device with an ADC, clock and carrier recovery, Viterbi decoding and Reed-Solomon forward error correction", "year": "1996", "venue": "IEEE Transactions on Consumer Electronics", "citations": [], "references": [], "authors": ["M. Haas", "F. Kuttner", "F. Frieling", "G. Hobbach", "H. Kriedt", "K. Mueller", "C. v. Reventlow"], "_id": {"$oid": "5797a8a9c60b4bee2df286ff"}}, {"index": "539089bb20f70186a0d9883c", "title": "Evaluation and Design of Filters Using a Taylor Series Expansion", "abstract": "We describe a new method for analyzing, classifying, and evaluating filters that can be applied to interpolation filters as well as to arbitrary derivative filters of any order. Our analysis is based on the Taylor series expansion of the convolution sum. Our analysis shows the need and derives the method for the normalization of derivative filter weights. Under certain minimal restrictions of the underlying function, we are able to compute tight absolute error bounds of the reconstruction process. We demonstrate the utilization of our methods to the analysis of the class of cubic BC-spline filters. As our technique is not restricted to interpolation filters, we are able to show that the Catmull-Rom spline filter and its derivative are the most accurate reconstruction and derivative filters, respectively, among the class of BC-spline filters. We also present a new derivative filter which features better spatial accuracy than any derivative BC-spline filter, and is optimal within our framework. We conclude by demonstrating the use of these optimal filters for accurate interpolation and gradient estimation in volume rendering.", "year": "1997", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["5390975920f70186a0dfc72b", "5390979920f70186a0e00525", "5390980720f70186a0e02058", "5390a2be20f70186a0e65015", "5390a6b120f70186a0e85ed8", "5390b24420f70186a0ee7413", "5390b24420f70186a0ee7756", "5390b7ff20f70186a0f276c1", "5390b86b20f70186a0f28148", "5390b86b20f70186a0f2814c", "5390b95520f70186a0f2f749", "5590ce4a0cf237666fc28d40", "539087e620f70186a0d6752c", "539087eb20f70186a0d6c073", "539087eb20f70186a0d6c04e", "539087eb20f70186a0d6c078", "539087eb20f70186a0d6c0e9", "539087f820f70186a0d72a33", "5390880720f70186a0d79c24", "5390880720f70186a0d79c21", "5390893e20f70186a0d92ed7", "539089ab20f70186a0d96b42", "539089bb20f70186a0d98878", "539089bb20f70186a0d98893", "539089bb20f70186a0d988b1", "53908ae020f70186a0dadc32"], "references": ["539087a520f70186a0d49123", "539087c720f70186a0d56c26", "539087d920f70186a0d6092d", "5390881220f70186a0d7ec9d", "5390881220f70186a0d7ecbb", "5390878720f70186a0d36057", "539089bb20f70186a0d9882d", "539089bb20f70186a0d98824", "5390879520f70186a0d3e9ad", "5390958a20f70186a0defa93"], "authors": ["Torsten M\u00f6ller", "Raghu Machiraju", "Klaus Mueller", "Roni Yagel"], "_id": {"$oid": "5797a691c60b4bee2dd90111"}}, {"index": "5390b5fa20f70186a0f10cdd", "title": "A low-cost DVB compliant Viterbi and Reed Solomon decoder", "abstract": "A low-cost DVB compliant Viterbi and Reed Solomon decoder applicable for DVB signals on a satellite is described. The circuit is a fully integrated digital channel decoder with a Viterbi decoder, Reed Solomon forward error correction and additional digital timing and carrier recovery", "year": "1997", "venue": "IEEE Transactions on Consumer Electronics", "citations": ["539089bb20f70186a0d98024"], "references": [], "authors": ["K. Mueller", "F. Frieling", "H. Kriedt", "C. von Reventlow", "R. Schwendt", "M. Haas", "F. Kuttner", "H. Dawid", "O. Joeressen", "U. Lambrette", "M. Vaupel", "H. Meyr"], "_id": {"$oid": "5797a706c60b4bee2dde4d26"}}, {"index": "539087e620f70186a0d67561", "title": "An anti-aliasing technique for splatting", "abstract": "", "year": "1997", "venue": "VIS '97 Proceedings of the 8th conference on Visualization '97", "citations": ["5390975920f70186a0dfcbda", "5390979920f70186a0e0052d", "539098b820f70186a0e0a6ef", "53909e7c20f70186a0e2bbd6", "5390b86b20f70186a0f2813e", "5390b86b20f70186a0f28155", "5390b86b20f70186a0f28126", "539087eb20f70186a0d6a620", "539087eb20f70186a0d6c05b", "539087eb20f70186a0d6c059", "539087eb20f70186a0d6c0c0", "5390880220f70186a0d77fd9", "5390881720f70186a0d7fc22", "5390881820f70186a0d8164e", "5390893e20f70186a0d92eda", "539089ab20f70186a0d96a88", "539089ab20f70186a0d96ab6", "539089bb20f70186a0d98858", "539089bb20f70186a0d988cb", "53908bcc20f70186a0dc5719", "539095bb20f70186a0df285e"], "references": ["539087a120f70186a0d4748f", "539087ae20f70186a0d4da93", "539087c720f70186a0d56f63", "539087c720f70186a0d5842e", "539087d920f70186a0d6092a", "539087d920f70186a0d6092d", "539087dd20f70186a0d62837", "5390878320f70186a0d325d2", "5390878720f70186a0d36057", "5390879220f70186a0d3d25d", "5390879920f70186a0d41b8b", "5390879920f70186a0d4203f", "539087fe20f70186a0d74a0a", "5390881220f70186a0d7ec9d", "5390882120f70186a0d857bb", "539089bb20f70186a0d987f9", "539089bb20f70186a0d9881d", "539089bb20f70186a0d98824", "53908bcc20f70186a0dc6cc4", "5390940220f70186a0de84da", "5390958a20f70186a0def783", "5390958a20f70186a0def76a", "5390958a20f70186a0defa93"], "authors": ["J. Edward Swan", "II", "Klaus Mueller", "Torsten M\u00f6ller", "Naeem Shareef", "Roger Crawfis", "Roni Yagel"], "_id": {"$oid": "5797a7d0c60b4bee2de71956"}}, {"index": "539087e620f70186a0d6752c", "title": "A comparison of normal estimation schemes", "abstract": "", "year": "1997", "venue": "VIS '97 Proceedings of the 8th conference on Visualization '97", "citations": ["5390979920f70186a0e00526", "5390979920f70186a0e0119e", "53909a9320f70186a0e21a99", "53909e7c20f70186a0e2bbd6", "53909e7c20f70186a0e2c0e2", "5390a06e20f70186a0e4c3a9", "5390a30b20f70186a0e69775", "5390ac1820f70186a0eb32be", "5390b00c20f70186a0ed4cb0", "5390b29820f70186a0ee957f", "5390b2fc20f70186a0eeda92", "5390b7ff20f70186a0f278de", "5390b7ff20f70186a0f278d7", "5390b86b20f70186a0f28124", "5390b86b20f70186a0f28125", "5390b95520f70186a0f2f749", "5390b95520f70186a0f2f792", "539087eb20f70186a0d6c063", "539087eb20f70186a0d6c078", "539087f820f70186a0d72a72", "539087f820f70186a0d72a33", "5390880720f70186a0d79c21", "5390881820f70186a0d8164c", "539089ab20f70186a0d96ab6", "539089ab20f70186a0d96b61", "539089bb20f70186a0d98875", "539089bb20f70186a0d988b6", "5390956e20f70186a0dedaac"], "references": ["539087c720f70186a0d56c26", "539087d920f70186a0d6092a", "5390878720f70186a0d34653", "5390878720f70186a0d36057", "5390879520f70186a0d3e9ad", "5390879920f70186a0d41b8b", "5390881220f70186a0d7ec9d", "539089bb20f70186a0d9882d", "539089bb20f70186a0d9883c", "539089bb20f70186a0d98824", "5390958a20f70186a0defa93"], "authors": ["Torsten M\u00f6ller", "Raghu Machiraju", "Klaus Mueller", "Roni Yagel"], "_id": {"$oid": "5797a8cac60b4bee2df42786"}}, {"index": "539087eb20f70186a0d6c0c0", "title": "Eliminating popping artifacts in sheet buffer-based splatting", "abstract": "", "year": "1998", "venue": "Proceedings of the conference on Visualization '98", "citations": ["5390979920f70186a0e0052d", "5390979920f70186a0e00558", "53909e7c20f70186a0e2bbd6", "5390a7f520f70186a0e942e6", "5390b86b20f70186a0f280d9", "5390b86b20f70186a0f28155", "5390b86b20f70186a0f28126", "5590c5e40cf2baaad9716723", "539087f820f70186a0d72a72", "5390880720f70186a0d79c1e", "5390880720f70186a0d79c21", "5390881820f70186a0d8164b", "5390881820f70186a0d8164e", "5390893e20f70186a0d92ed7", "539089ab20f70186a0d96a88", "539089ab20f70186a0d96ab6", "539089ab20f70186a0d96b42", "539089ab20f70186a0d96b33", "539089bb20f70186a0d98870", "539089bb20f70186a0d988cb", "53908b4920f70186a0dbc860", "53908b6c20f70186a0dbd34c", "5390958920f70186a0def08c"], "references": ["539087a120f70186a0d4748f", "539087a120f70186a0d47499", "539087ae20f70186a0d4cd20", "539087ae20f70186a0d4da93", "539087be20f70186a0d51ef0", "539087c720f70186a0d56f63", "539087c720f70186a0d5842a", "539087c720f70186a0d5842e", "539087d920f70186a0d6092a", "539087d920f70186a0d60927", "539087dd20f70186a0d62837", "539087dd20f70186a0d62a33", "539087e620f70186a0d67561", "5390879920f70186a0d41b8b", "539087fe20f70186a0d74a0a", "539089bb20f70186a0d987f7", "539089bb20f70186a0d98858", "539089bb20f70186a0d98e1d", "53908bad20f70186a0dc3150", "53908bad20f70186a0dc315c", "53908bcc20f70186a0dc6cc4", "5390958a20f70186a0def783", "5390958a20f70186a0def76a"], "authors": ["Klaus Mueller", "Roger Crawfis"], "_id": {"$oid": "5797a579c60b4bede9ea37f5"}}, {"index": "539087eb20f70186a0d6c0c0", "title": "Eliminating popping artifacts in sheet buffer-based splatting", "abstract": "", "year": "1998", "venue": "Proceedings of the conference on Visualization '98", "citations": ["5390979920f70186a0e0052d", "5390979920f70186a0e00558", "53909e7c20f70186a0e2bbd6", "5390a7f520f70186a0e942e6", "5390b86b20f70186a0f280d9", "5390b86b20f70186a0f28155", "5390b86b20f70186a0f28126", "5590c5e40cf2baaad9716723", "539087f820f70186a0d72a72", "5390880720f70186a0d79c1e", "5390880720f70186a0d79c21", "5390881820f70186a0d8164b", "5390881820f70186a0d8164e", "5390893e20f70186a0d92ed7", "539089ab20f70186a0d96a88", "539089ab20f70186a0d96ab6", "539089ab20f70186a0d96b42", "539089ab20f70186a0d96b33", "539089bb20f70186a0d98870", "539089bb20f70186a0d988cb", "53908b4920f70186a0dbc860", "53908b6c20f70186a0dbd34c", "5390958920f70186a0def08c"], "references": ["539087a120f70186a0d4748f", "539087a120f70186a0d47499", "539087ae20f70186a0d4cd20", "539087ae20f70186a0d4da93", "539087be20f70186a0d51ef0", "539087c720f70186a0d56f63", "539087c720f70186a0d5842a", "539087c720f70186a0d5842e", "539087d920f70186a0d6092a", "539087d920f70186a0d60927", "539087dd20f70186a0d62837", "539087dd20f70186a0d62a33", "539087e620f70186a0d67561", "5390879920f70186a0d41b8b", "539087fe20f70186a0d74a0a", "539089bb20f70186a0d987f7", "539089bb20f70186a0d98858", "539089bb20f70186a0d98e1d", "53908bad20f70186a0dc3150", "53908bad20f70186a0dc315c", "53908bcc20f70186a0dc6cc4", "5390958a20f70186a0def783", "5390958a20f70186a0def76a"], "authors": ["Klaus Mueller", "Roger Crawfis"], "_id": {"$oid": "5797a64cc60b4bee2dd59008"}}, {"index": "5390940220f70186a0de8bdb", "title": "Fast and accurate three-dimensional reconstruction from cone-beam projection data using algebraic methods", "abstract": "", "year": "1998", "venue": "Fast and accurate three-dimensional reconstruction from cone-beam projection data using algebraic methods", "citations": ["5390a72220f70186a0e89bc3", "5390a9a520f70186a0ea610e", "5390aca820f70186a0eb885f", "5390aefc20f70186a0ecd7c3", "5390b20120f70186a0ee5538"], "references": [], "authors": ["Roni Yagel", "Klaus Mueller"], "_id": {"$oid": "5797a6c3c60b4bee2ddb70b2"}}, {"index": "539087eb20f70186a0d6c078", "title": "Design of accurate and smooth filters for function and derivative reconstruction", "abstract": "", "year": "1998", "venue": "VVS '98 Proceedings of the 1998 IEEE symposium on Volume visualization", "citations": ["5390979920f70186a0e00526", "539098b820f70186a0e0a6f9", "539098b820f70186a0e0a6ea", "539098b820f70186a0e0a8fb", "5390990f20f70186a0e10e32", "53909a9320f70186a0e21a99", "53909e7c20f70186a0e2c0e2", "53909f8c20f70186a0e3f7a6", "5390a25820f70186a0e60298", "5390ac1820f70186a0eb32be", "5390adfd20f70186a0ec5f1d", "5390afc920f70186a0ed26c5", "5390b7ff20f70186a0f276b1", "5390b7ff20f70186a0f278d7", "5390b86b20f70186a0f28125", "5390b86b20f70186a0f2812c", "5390b95520f70186a0f2f792", "5390b9d520f70186a0f30786", "5390bda020f70186a0f4766b", "55902621612c8aa08ca8be42", "539087eb20f70186a0d6c0e9", "5390880720f70186a0d79c24", "539089ab20f70186a0d96a90", "539089ab20f70186a0d96a91", "539089bb20f70186a0d98878", "539089bb20f70186a0d988b1", "539089bb20f70186a0d988b6", "53908a4020f70186a0d9d8af"], "references": ["539087c720f70186a0d56c26", "539087e620f70186a0d6752c", "5390878720f70186a0d36057", "5390879220f70186a0d3d25d", "5390879520f70186a0d3e9ad", "539087eb20f70186a0d6c0e9", "5390881220f70186a0d7ecbb", "5390881220f70186a0d7ec9d", "539089bb20f70186a0d9882d", "539089bb20f70186a0d9883c", "539089bb20f70186a0d98824", "5390958a20f70186a0def769", "5390958a20f70186a0defa93"], "authors": ["Torsten M\u00f6ller", "Klaus Mueller", "Yair Kurzion", "Raghu Machiraju", "Roni Yagel"], "_id": {"$oid": "5797a71ec60b4bee2ddf5ac1"}}, {"index": "53908b0220f70186a0db0ae2", "title": "Information Management for Life Cycle Assessment Using Smart Agents", "abstract": "", "year": "1998", "venue": "PROLAMAT '98 Proceedings of the Tenth International IFIP WG5.2/WG5.3 Conference on Globalization of Manufacturing in the Digital Communications Era of the 21st Century: Innovation, Agility, and the Virtual Enterprise", "citations": ["5390aeba20f70186a0ecb7d3"], "references": [], "authors": ["G. Seliger", "T. Keil", "D. Kruetzfeldt", "K. Mueller", " Perlewitz"], "_id": {"$oid": "5797a848c60b4bee2ded55e6"}}, {"index": "539089bb20f70186a0d98858", "title": "Splatting Errors and Antialiasing", "abstract": "This paper describes three new results for volume rendering algorithms utilizing splatting. First, an antialiasing extension to the basic splatting algorithm is introduced that mitigates the spatial aliasing for high-resolution volumes. Aliasing can be severe for high-resolution volumes or volumes where a high depth of field leads to converging samples along the perspective axis. Next, an analysis of the common approximation errors in the splatting process for perspective viewing is presented. In this context, we give different implementations, distinguished by efficiency and accuracy, for adding the splat contributions to the image plane. We then present new results in controlling the splatting errors and also show their behavior in the framework of our new antialiasing technique. Finally, current work in progress on extensions to splatting for temporal antialiasing is demonstrated. Here, we present a simple but highly effective scheme for adding motion blur to fast moving volumes.", "year": "1998", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["5390979920f70186a0e0052d", "5390980720f70186a0e0205f", "53909a9320f70186a0e21a99", "5390a7f520f70186a0e942e6", "5390b7fe20f70186a0f26588", "5390b7ff20f70186a0f278dc", "5390b86b20f70186a0f280d9", "5390b86b20f70186a0f28155", "5390b86b20f70186a0f28126", "539087eb20f70186a0d6c05b", "539087eb20f70186a0d6c0c0", "5390881220f70186a0d7e176", "5390881220f70186a0d7e17e", "5390881720f70186a0d7fc22", "5390893e20f70186a0d9272f", "539089ab20f70186a0d96b33", "539089bb20f70186a0d98870", "539089bb20f70186a0d988cb", "53908b4920f70186a0dbc860", "53908b6c20f70186a0dbd34c", "5390962020f70186a0df49f0"], "references": ["539087a120f70186a0d4748f", "539087ae20f70186a0d4da93", "539087c720f70186a0d56f63", "539087d920f70186a0d60927", "539087dd20f70186a0d62837", "539087e620f70186a0d67561", "539087fe20f70186a0d74a0a", "5390881220f70186a0d7ec9d", "539089bb20f70186a0d987f7", "539089bb20f70186a0d987f9", "539089bb20f70186a0d9881d", "5390879920f70186a0d41b8b", "5390879920f70186a0d4203f", "539089bb20f70186a0d98e9b", "5390958a20f70186a0def783"], "authors": ["Klaus Mueller", "Torsten M\u00f6ller", "J. Edward Swan II", "Roger Crawfis", "Naeem Shareef", "Roni Yagel"], "_id": {"$oid": "5797a84fc60b4bee2dedb002"}}, {"index": "53908bcc20f70186a0dc6d55", "title": "Splatting Without The Blur", "abstract": "Splatting is a volume rendering algorithm that combines efficientvolume projection with a sparse data representation: Onlyvoxels that have values inside the iso-range need to be considered,and these voxels can be projected via efficient rasterizationschemes. In splatting, each projected voxel is represented as aradially symmetric interpolation kernel, equivalent to a fuzzy ball.Projecting such a basis function leaves a fuzzy impression, called afootprint or splat, on the screen. Splatting traditionally classifiesand shades the voxels prior to projection, and thus each voxel footprintis weighted by the assigned voxel color and opacity. Projectingthese fuzzy color balls provides a uniform screen image forhomogeneous object regions, but leads to a blurry appearance ofobject edges. The latter is clearly undesirable, especially when theview is zoomed on the object. In this work, we manipulate the renderingpipeline of splatting by performing the classification andshading process after the voxels have been projected onto thescreen. In this way, volume contributions outside the iso-rangenever affect the image. Since shading requires gradients, we notonly splat the density volume, using regular splats, but we alsoproject the gradient volume, using gradient splats. However, alternativeto gradient splats, we can also compute the gradients on theprojection plane, using central differencing. This latter schemecuts the number of footprint rasterization by a factor of four, sinceonly the voxel densities have to be projected. Our new method rendersobjects with crisp edges and well-preserved surface detail.Added overhead is the calculation of the screen gradients and theper-pixel shading. Both of these operations, however, may be performedusing fast techniques employing lookup tables.", "year": "1999", "venue": "VISUALIZATION '99 Proceedings of the 10th IEEE Visualization 1999 Conference (VIS '99)", "citations": [], "references": [], "authors": ["Klaus Mueller", "Torsten M\u00f6ller", "Roger Crawfis"], "_id": {"$oid": "5797a56bc60b4bede9e9b1f0"}}, {"index": "53908bcc20f70186a0dc6d55", "title": "Splatting Without The Blur", "abstract": "Splatting is a volume rendering algorithm that combines efficientvolume projection with a sparse data representation: Onlyvoxels that have values inside the iso-range need to be considered,and these voxels can be projected via efficient rasterizationschemes. In splatting, each projected voxel is represented as aradially symmetric interpolation kernel, equivalent to a fuzzy ball.Projecting such a basis function leaves a fuzzy impression, called afootprint or splat, on the screen. Splatting traditionally classifiesand shades the voxels prior to projection, and thus each voxel footprintis weighted by the assigned voxel color and opacity. Projectingthese fuzzy color balls provides a uniform screen image forhomogeneous object regions, but leads to a blurry appearance ofobject edges. The latter is clearly undesirable, especially when theview is zoomed on the object. In this work, we manipulate the renderingpipeline of splatting by performing the classification andshading process after the voxels have been projected onto thescreen. In this way, volume contributions outside the iso-rangenever affect the image. Since shading requires gradients, we notonly splat the density volume, using regular splats, but we alsoproject the gradient volume, using gradient splats. However, alternativeto gradient splats, we can also compute the gradients on theprojection plane, using central differencing. This latter schemecuts the number of footprint rasterization by a factor of four, sinceonly the voxel densities have to be projected. Our new method rendersobjects with crisp edges and well-preserved surface detail.Added overhead is the calculation of the screen gradients and theper-pixel shading. Both of these operations, however, may be performedusing fast techniques employing lookup tables.", "year": "1999", "venue": "VISUALIZATION '99 Proceedings of the 10th IEEE Visualization 1999 Conference (VIS '99)", "citations": [], "references": [], "authors": ["Klaus Mueller", "Torsten M\u00f6ller", "Roger Crawfis"], "_id": {"$oid": "5797a643c60b4bee2dd50a03"}}, {"index": "539089bb20f70186a0d98870", "title": "High-Quality Splatting on Rectilinear Grids with Efficient Culling of Occluded Voxels", "abstract": "Splatting is a popular volume rendering algorithm that pairs good image quality with an efficient volume projection scheme. The current axis-aligned sheet-buffer approach, however, bears certain inaccuracies. The effect of these is less noticeable in still images, but clearly revealed in animated viewing, where disturbing popping of object brightness occurs at certain view angle transitions. In previous work, we presented a new variant of sheet-buffered splatting in which the compositing sheets are oriented parallel to the image plane. This scheme not only eliminates the condition for popping, but also produces images of higher quality. In this paper, we summarize this new paradigm and extend it in a number of ways. We devise a new solution to render rectilinear grids of equivalent cost to the traditional approach that treats the anisotropic volume as being warped into a cubic grid. This enables us to use the usual radially symmetric kernels, which can be projected without inaccuracies. Next, current splatting approaches necessitate the projection of all voxels in the iso-interval(s), although only a subset of these voxels may eventually be visible in the final image. To eliminate these wasteful computations we propose a novel front-to-back approach that employs an occlusion map to determine if a splat contributes to the image before it is projected, thus skipping occluded splats. Additional measures are presented for further speedups. In addition, we present an efficient list-based volume traversal scheme that facilitates the quick modification of transfer functions and iso-values.", "year": "1999", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["5390979920f70186a0e0052d", "5390979920f70186a0e0119e", "5390981d20f70186a0e05118", "539098b820f70186a0e0a6e0", "539098b820f70186a0e0a6ee", "53909a9320f70186a0e21a8d", "53909e7c20f70186a0e2bbd6", "5390a7f520f70186a0e942e6", "5390a9a520f70186a0ea5e0b", "5390b7ff20f70186a0f278be", "5390b7ff20f70186a0f27cea", "5390b86b20f70186a0f28155", "5390b86b20f70186a0f28126", "5390b95520f70186a0f2f772", "5590c5e40cf2baaad9716723", "539087f820f70186a0d72a72", "5390880220f70186a0d77f55", "5390880720f70186a0d78af7", "5390880720f70186a0d79c21", "5390881220f70186a0d7e17e", "5390893e20f70186a0d92ed7", "539089ab20f70186a0d96aa4", "539089ab20f70186a0d96b41", "539089ab20f70186a0d96b42", "539089ab20f70186a0d96b33", "53908ae020f70186a0dad763", "53908b4920f70186a0dbb8b7", "53908b4920f70186a0dbc860", "53908bcc20f70186a0dc5719"], "references": ["539087a120f70186a0d4748f", "539087a120f70186a0d47499", "539087ae20f70186a0d4cd20", "539087ae20f70186a0d4da93", "539087be20f70186a0d51ef0", "539087c720f70186a0d56f63", "539087c720f70186a0d5842e", "539087c720f70186a0d58908", "539087d920f70186a0d60927", "539087dd20f70186a0d62837", "539087dd20f70186a0d62a33", "5390878320f70186a0d325d2", "539087eb20f70186a0d6c0c0", "539087fe20f70186a0d74a0a", "5390881220f70186a0d7ec95", "5390881220f70186a0d7ec9d", "539089bb20f70186a0d987f7", "5390879920f70186a0d41b8b", "539089bb20f70186a0d98858", "539089bb20f70186a0d98e1d", "53908bad20f70186a0dc3150", "53908bad20f70186a0dc315c", "53908bcc20f70186a0dc6ccc", "53908bcc20f70186a0dc6cc4", "5390958a20f70186a0def783", "5390958a20f70186a0def76a", "5390958a20f70186a0defa91"], "authors": ["Klaus Mueller", "Naeem Shareef", "Jian Huang", "Roger Crawfis"], "_id": {"$oid": "5797a6b1c60b4bee2ddaabb0"}}, {"index": "5390aeba20f70186a0ecb7d3", "title": "Product and process planning for recycling", "abstract": "Low gains for disassembled components and materials as well as high efforts make a profitable recycling difficult. This paper presents two approaches to improve the efficiency of disassembly and recycling. One method supports the design of new products for ease of recycling while the other one supports the planning of robust recycling systems.", "year": "1999", "venue": "ecodesign'99 Proceedings of the First international conference on Environmentally conscious design and inverse manufacturing", "citations": [], "references": ["53908b0220f70186a0db0ae2"], "authors": ["G. Seliger", "K. Mueller", "H. Perlewitz"], "_id": {"$oid": "5797a7f2c60b4bee2de8edbe"}}, {"index": "539087f820f70186a0d72a72", "title": "Splatting without the blur", "abstract": "Splatting is a volume rendering algorithm that combines efficient volume projection with a sparse data representation: Only voxels that have values inside the iso-range need to be considered, and these voxels can be projected via efficient rasterization schemes. In splatting, each projected voxel is represented as a radially symmetric interpolation kernel, equivalent to a fuzzy ball. Projecting such a basis function leaves a fuzzy impression, called a footprint or splat, on the screen. Splatting traditionally classifies and shades the voxels prior to projection, and thus each voxel footprint is weighted by the assigned voxel color and opacity. Projecting these fuzzy color balls provides a uniform screen image for homogeneous object regions, but leads to a blurry appearance of object edges. The latter is clearly undesirable, especially when the view is zoomed on the object. In this work, we manipulate the rendering pipeline of splatting by performing the classification and shading process after the voxels have been projected onto the screen. In this way, volume contributions outside the iso-range never affect the image. Since shading requires gradients, we not only splat the density volume, using regular splats, but we also project the gradient volume, using gradient splats. However, alternative to gradient splats, we can also compute the gradients on the projection plane, using central differencing. This latter scheme cuts the number of footprint rasterization by a factor of four, since only the voxel densities have to be projected. Our new method renders objects with crisp edges and well-preserved surface detail. Added overhead is the calculation of the screen gradients and the per-pixel shading. Both of these operations, however, may be performed using fast techniques employing lookup tables.", "year": "1999", "venue": "VIS '99 Proceedings of the conference on Visualization '99: celebrating ten years", "citations": ["5390975920f70186a0dfcbda", "5390979920f70186a0e0052d", "5390979920f70186a0e00531", "5390979920f70186a0e00558", "5390979920f70186a0e0119e", "5390981d20f70186a0e05118", "539098b820f70186a0e0a6ef", "539098b820f70186a0e0a8fb", "53909e7c20f70186a0e2bbd6", "5390a7f520f70186a0e942e6", "5390b7ff20f70186a0f278be", "5390b86b20f70186a0f280ef", "5390b86b20f70186a0f28155", "5390b86b20f70186a0f2815e", "5390b86b20f70186a0f28126", "5590ce4a0cf237666fc28d40", "5390880720f70186a0d79c1e", "5390880720f70186a0d79c21", "5390881220f70186a0d7e17e", "5390881720f70186a0d8040c", "5390881820f70186a0d8164b", "5390893e20f70186a0d92ed7", "539089ab20f70186a0d96a88", "539089ab20f70186a0d96ab6", "539089ab20f70186a0d96b42", "539089ab20f70186a0d96b33", "539089bb20f70186a0d988db", "539089bb20f70186a0d988cb", "53908b4920f70186a0dbc860", "53908b6c20f70186a0dbd34c", "53908bcc20f70186a0dc5719", "53908e0020f70186a0dd4a1b", "5390956e20f70186a0dedaac"], "references": ["539087a120f70186a0d47499", "539087ae20f70186a0d4da93", "539087be20f70186a0d51ef0", "539087c720f70186a0d56f63", "539087c720f70186a0d5842e", "539087d920f70186a0d60927", "539087d920f70186a0d60c92", "539087dd20f70186a0d62837", "539087e120f70186a0d65805", "539087e120f70186a0d65817", "539087e620f70186a0d6752c", "539087eb20f70186a0d6a615", "539087eb20f70186a0d6c05b", "539087eb20f70186a0d6c076", "539087eb20f70186a0d6c0c6", "539087eb20f70186a0d6c0be", "539087eb20f70186a0d6c0c0", "5390878720f70186a0d34653", "5390878720f70186a0d36057", "5390879220f70186a0d3d937", "5390879620f70186a0d4026b", "5390879920f70186a0d41b8b", "539087fe20f70186a0d74a0a", "5390881220f70186a0d7ec9d", "539089bb20f70186a0d987f7", "539089bb20f70186a0d98824", "539089bb20f70186a0d98870", "539089bb20f70186a0d993e4", "53908b9320f70186a0dc153f", "53908bad20f70186a0dc3150", "5390958a20f70186a0def783", "5390958a20f70186a0defa8a"], "authors": ["Klaus Mueller", "Torsten M\u00f6ller", "Roger Crawfis"], "_id": {"$oid": "5797a845c60b4bee2ded2a6f"}}, {"index": "53908b1820f70186a0db565f", "title": "Tools for computer-supported learning in organisations", "abstract": "", "year": "1999", "venue": "Proceedings of the HCI International '99 (the 8th International Conference on Human-Computer Interaction) on Human-Computer Interaction: Communication, Cooperation, and Application Design-Volume 2 - Volume 2", "citations": [], "references": [], "authors": ["Ernst A. Hartmann", "Dirk Sistenich", "Klaus Mueller", "Michael Gerads", "Holger Sickel"], "_id": {"$oid": "5797a889c60b4bee2df0d11a"}}, {"index": "53908bcc20f70186a0dc6cf3", "title": "Optimized Software Splatting Using FastSplats on Rectilinear Grid", "abstract": "Splatting is widely applied in many areas, including volume,point-based, and image-based rendering. Improvements tosplatting, such as eliminating popping and color bleeding,occlusion-based acceleration, post-rendering classification andshading, have all been recently accomplished. These improvementsshare a common need for efficient framebuffer accesses. Wepresent an optimized software splatting package, using a newlydesigned primitive, called FastSplat, to scan-convert footprints.Our approach does not use texture mapping hardware, butsupports the whole pipeline in memory. In such an integratedpipeline, we are then able to study the optimization strategies andaddress image quality issues. While this research is meant for astudy of the inherent trade-off of splatting, our renderer, purley insoftware, achieves 3 to 5 times speedups over a top-end texturehardware (for opaque data sets) implementation. We furtherpropose a way of efficient occlusion culling using a summed areatable of opacity. 3D solid texturing and bump mapping capabilitiesare demonstrated to show the flexibility of such an integratedrendering pipeline. A detailed numerical error analysis, inaddition to the performance and storage issues, is also presented.Our approach requires low storage and uses simple operations.Thus, it is easily implementable in hardware.", "year": "2000", "venue": "VISUALIZATION '00 Proceedings of the 11th IEEE Visualization 2000 Conference (VIS 2000)", "citations": [], "references": [], "authors": ["Jian Huang", "Klaus Mueller", "Naeem Shareef", "Roger Crawfis"], "_id": {"$oid": "5797a6b9c60b4bee2ddb0568"}}, {"index": "5390881220f70186a0d7e17e", "title": "FastSplats: optimized splatting on rectilinear grids", "abstract": "", "year": "2000", "venue": "Proceedings of the conference on Visualization '00", "citations": ["5390979920f70186a0e0052d", "5390979920f70186a0e00537", "5390979920f70186a0e0119e", "539098b820f70186a0e0a6e3", "53909a9320f70186a0e21a8d", "53909e7c20f70186a0e2bbd6", "5390a01420f70186a0e47ddf", "5390a7f520f70186a0e942e6", "5390b7ff20f70186a0f2772a", "5390b86b20f70186a0f28155", "5390b86b20f70186a0f28126", "5390880720f70186a0d79c21", "539089ab20f70186a0d96aa4", "539089ab20f70186a0d96b42", "539089ab20f70186a0d96b33", "53908b4920f70186a0dbc860", "53908bcc20f70186a0dc5719", "53908cde20f70186a0dcd8c7"], "references": ["539087a120f70186a0d47499", "539087c720f70186a0d5842e", "539087e120f70186a0d65836", "539087eb20f70186a0d6a62b", "539087f320f70186a0d70fa5", "539087f820f70186a0d72a32", "539087f820f70186a0d72a72", "539087fe20f70186a0d73df2", "539087fe20f70186a0d74a0a", "5390880220f70186a0d77fd9", "5390880220f70186a0d77fd5", "5390879520f70186a0d3e9ad", "5390879920f70186a0d41b8b", "539089bb20f70186a0d987f7", "539089bb20f70186a0d9881d", "539089bb20f70186a0d98858", "539089bb20f70186a0d98870", "53908bad20f70186a0dc3150", "5390958a20f70186a0def783"], "authors": ["Jian Huang", "Roger Crawfis", "Naeem Shareef", "Klaus Mueller"], "_id": {"$oid": "5797a72ac60b4bee2ddfe790"}}, {"index": "5390880720f70186a0d79c21", "title": "A practical evaluation of popular volume rendering algorithms", "abstract": "", "year": "2000", "venue": "VVS '00 Proceedings of the 2000 IEEE symposium on Volume visualization", "citations": ["5390979920f70186a0e0055b", "5390981d20f70186a0e05118", "5390985d20f70186a0e06edc", "539098b820f70186a0e0a6ee", "539098b820f70186a0e0a6ea", "53909a9320f70186a0e21a7b", "53909a9320f70186a0e21a8d", "53909e7c20f70186a0e2bbd6", "53909eef20f70186a0e36a76", "5390a1bc20f70186a0e563d4", "5390a30b20f70186a0e6af52", "5390a63c20f70186a0e8214d", "5390a72220f70186a0e89dec", "5390a72220f70186a0e8ab26", "5390a72220f70186a0e8b008", "5390a7f520f70186a0e942b8", "5390a9a520f70186a0ea5e0b", "5390a9a520f70186a0ea69b8", "5390ae2e20f70186a0ec8917", "5390b04120f70186a0ed8806", "5390b48420f70186a0efb99f", "5390b7ff20f70186a0f276d1", "5390b7ff20f70186a0f27ced", "5390b7ff20f70186a0f27cee", "5390b86b20f70186a0f2813e", "5390b86b20f70186a0f28126", "5390b95520f70186a0f2f749", "5390b95520f70186a0f2f75c", "5390881820f70186a0d81648", "5390881820f70186a0d81649", "5390881820f70186a0d8164b", "5390893e20f70186a0d92ed1", "5390893e20f70186a0d92edb", "539089ab20f70186a0d96aa4", "539089ab20f70186a0d96acd", "539089ab20f70186a0d96b42", "539089ab20f70186a0d96b33", "53908ae020f70186a0dadc32", "53908b4920f70186a0dbc860", "53908b6c20f70186a0dbd34c", "53908bcc20f70186a0dc5718", "5390958920f70186a0def081"], "references": ["539087ae20f70186a0d4cd20", "539087c720f70186a0d56f12", "539087c720f70186a0d56f63", "539087c720f70186a0d5842e", "539087d920f70186a0d60927", "5390b95520f70186a0f2f6d2", "539087e620f70186a0d6752c", "539087e720f70186a0d69475", "539087eb20f70186a0d6a615", "539087eb20f70186a0d6b607", "539087eb20f70186a0d6c05b", "539087eb20f70186a0d6c076", "539087eb20f70186a0d6c0c6", "539087eb20f70186a0d6c0be", "539087eb20f70186a0d6c0c0", "539087f820f70186a0d72a41", "539087f820f70186a0d72a72", "5390878720f70186a0d34653", "5390878720f70186a0d36057", "5390879220f70186a0d3d937", "5390879920f70186a0d41b8b", "5390881220f70186a0d7e17e", "5390881220f70186a0d7ec95", "5390881220f70186a0d7ec9b", "5390881220f70186a0d7ec9d", "539089bb20f70186a0d987f7", "539089bb20f70186a0d9883c", "539089bb20f70186a0d98824", "539089bb20f70186a0d98870", "539089bb20f70186a0d98d7a", "539089bb20f70186a0d993e4", "53908b9320f70186a0dc153f", "53908bad20f70186a0dc3150", "53908bad20f70186a0dc315c", "53908bcc20f70186a0dc6cc4", "5390958a20f70186a0def769", "5390958a20f70186a0def783", "5390958a20f70186a0def76a", "5390958a20f70186a0defa93", "5390958a20f70186a0defa8a"], "authors": ["Michael Mei\u00dfner", "Jian Huang", "Dirk Bartz", "Klaus Mueller", "Roger Crawfis"], "_id": {"$oid": "5797a842c60b4bee2ded142c"}}, {"index": "5390880720f70186a0d79c25", "title": "Volumetric backprojection", "abstract": "", "year": "2000", "venue": "VVS '00 Proceedings of the 2000 IEEE symposium on Volume visualization", "citations": ["53909eef20f70186a0e35910", "5390b86b20f70186a0f28126"], "references": ["539087b320f70186a0d51100", "539087c720f70186a0d5842e", "539087c720f70186a0d58417", "539087d320f70186a0d5d859", "539087d920f70186a0d6092a", "539087e120f70186a0d6582a", "539087e720f70186a0d69335", "539087eb20f70186a0d6a655", "539087eb20f70186a0d6c059", "539087eb20f70186a0d6c055", "539087f320f70186a0d70fa2", "539087f320f70186a0d70fa5", "5390880220f70186a0d76ce3", "5390878720f70186a0d34661", "5390878720f70186a0d36057", "5390881220f70186a0d7eca0", "539089bb20f70186a0d987f7", "539089bb20f70186a0d98df5", "53908bad20f70186a0dc3150", "53908f5b20f70186a0ddac4e"], "authors": ["Frank Dachille", "IX", "Klaus Mueller", "Arie Kaufman"], "_id": {"$oid": "5797a842c60b4bee2ded1430"}}, {"index": "539089ab20f70186a0d96ac9", "title": "Graphical strategies to convey functional relationships in the human brain: a case study", "abstract": "Brain imaging methods used in experimental brain research such as Positron Emission Tomography (PET) and Functional Magnetic Resonance (fMRI) require the analysis of large amounts of data. Exploratory statistical methods can be used to generate new hypotheses and to provide a reliable measure of a given effect. Typically, researchers report their findings by listing those regions which show significant statistical activity in a group of subjects under some experimental condition or task. A number of methods create statistical parametric maps (SPMs) of the brain on a voxelbasis. In our approach statistics are computed not on individual voxels but on predefined anatomical regions-of-interest (ROIs). A correlation coefficient is used to quantify similarity in response for various regions during an experimental setting. Since the functional inter-relationships can become rather complex and spatially widespread, they are best understood in the context of the underlying 3-D brain anatomy. However, despite the power of the 3-D model, the relative location of ROIs in 3-D can be obscured due the inherent problem of presenting 3-D spatial information on a 2-D screen. In order to address this problem, we have explored a number of visualization techniques to aid the brain researcher in exploring the spatial relationships of brain activity. In this paper, we present a novel 3-D interface that allows the interactive exploration of correlation datasets.", "year": "2001", "venue": "Proceedings of the conference on Visualization '01", "citations": [], "references": ["539087e120f70186a0d65878", "5390881220f70186a0d7ecaa"], "authors": ["Tomihisa Welsh", "Klaus Mueller", "Wei Zhu", "Nora Volkow", "Jeffrey Meade"], "_id": {"$oid": "5797a57ac60b4bede9ea46b8"}}, {"index": "539089ab20f70186a0d96ac9", "title": "Graphical strategies to convey functional relationships in the human brain: a case study", "abstract": "Brain imaging methods used in experimental brain research such as Positron Emission Tomography (PET) and Functional Magnetic Resonance (fMRI) require the analysis of large amounts of data. Exploratory statistical methods can be used to generate new hypotheses and to provide a reliable measure of a given effect. Typically, researchers report their findings by listing those regions which show significant statistical activity in a group of subjects under some experimental condition or task. A number of methods create statistical parametric maps (SPMs) of the brain on a voxelbasis. In our approach statistics are computed not on individual voxels but on predefined anatomical regions-of-interest (ROIs). A correlation coefficient is used to quantify similarity in response for various regions during an experimental setting. Since the functional inter-relationships can become rather complex and spatially widespread, they are best understood in the context of the underlying 3-D brain anatomy. However, despite the power of the 3-D model, the relative location of ROIs in 3-D can be obscured due the inherent problem of presenting 3-D spatial information on a 2-D screen. In order to address this problem, we have explored a number of visualization techniques to aid the brain researcher in exploring the spatial relationships of brain activity. In this paper, we present a novel 3-D interface that allows the interactive exploration of correlation datasets.", "year": "2001", "venue": "Proceedings of the conference on Visualization '01", "citations": [], "references": ["539087e120f70186a0d65878", "5390881220f70186a0d7ecaa"], "authors": ["Tomihisa Welsh", "Klaus Mueller", "Wei Zhu", "Nora Volkow", "Jeffrey Meade"], "_id": {"$oid": "5797a64dc60b4bee2dd59ecb"}}, {"index": "5390b86b20f70186a0f28126", "title": "Splatting with shadows", "abstract": "In this paper we describe an efficient approach to add shadows to volumetric scenes. The light emitted by the lightsource is properly attenuated by the intervening volumetric structures before it is reflected towards the eye. Both parallel and perspective lightsources can be efficiently and accurately modeled.We use a two-stage splatting approach. In the first stage, a light volume is constructed in O(N3) time, which is about the same time it takes to render a regular image. This light volume stores the volumetric attenuated light arriving at each grid voxel and only needs to be recomputed if the light source is moved. If only diffuse shading is required, then the contribution of any number of lightsources can be stored in the same space. The second stage is formed by the usual rendering pipeline. The only difference is that the light contributions are interpolated from the light volume, instead of using the constant light source intensity. Once the light volume is computed, the actual rendering is only marginally more expensive than in the unshadowed case. The rendered images, however, convey three-dimensional relationships much better and look considerably more realistic, which is clearly needed if volume graphics is to become a mainstream technology.", "year": "2001", "venue": "VG'01 Proceedings of the 2001 Eurographics conference on Volume Graphics", "citations": ["539098b820f70186a0e0a6e5", "539088b820f70186a0d8f3d5", "539089ab20f70186a0d96b36", "539089ab20f70186a0d96b33", "53908b4920f70186a0dbc861", "53908b4920f70186a0dbc860"], "references": ["539087ae20f70186a0d4da93", "539087c720f70186a0d56f63", "539087c720f70186a0d5842e", "539087c720f70186a0d58417", "5390878720f70186a0d34661", "5390878720f70186a0d34653", "5390878720f70186a0d35e7c", "5390879220f70186a0d3d937", "5390879520f70186a0d3e9ad", "5390879620f70186a0d402d5", "5390879920f70186a0d41b8b", "539087e620f70186a0d67561", "539087eb20f70186a0d6a657", "539087eb20f70186a0d6c055", "539087eb20f70186a0d6c0c0", "539087f820f70186a0d72a72", "539087fe20f70186a0d73dbe", "5390880220f70186a0d77f55", "5390880720f70186a0d79c21", "5390880720f70186a0d79c25", "5390880720f70186a0d7ab0a", "5390881220f70186a0d7e17e", "5390882c20f70186a0d8d82d", "539089bb20f70186a0d987f7", "539089bb20f70186a0d98858", "539089bb20f70186a0d98870", "539089bb20f70186a0d98da4", "53908bad20f70186a0dc2d17"], "authors": ["Manjushree Nulkar", "Klaus Mueller"], "_id": {"$oid": "5797a737c60b4bee2de07ef7"}}, {"index": "5390b86b20f70186a0f28136", "title": "Proceedings of the 2001 Eurographics conference on Volume Graphics", "abstract": "", "year": "2001", "venue": "VG'01 Proceedings of the 2001 Eurographics conference on Volume Graphics", "citations": [], "references": [], "authors": ["Klaus Mueller", "Arie E. Kaufman"], "_id": {"$oid": "5797a747c60b4bee2de14d86"}}, {"index": "5390b86b20f70186a0f28123", "title": "Proceedings of the 2001 Eurographics conference on Volume Graphics", "abstract": "", "year": "2001", "venue": "VG'01 Proceedings of the 2001 Eurographics conference on Volume Graphics", "citations": [], "references": [], "authors": ["Klaus Mueller", "Arie E. Kaufman"], "_id": {"$oid": "5797a776c60b4bee2de386c8"}}, {"index": "53908bcc20f70186a0dc556e", "title": "Interactive Transfer Function Modification for Volume Rendering Using Pre-Shaded Sample Runs", "abstract": "This paper describes a software-based method for interactive transfer function modification. Our approach exploits the fact that, in general, a user will rarely want to modify the viewpoint and the transfer functions at the same time. In that spirit, we optimize the latter by first fixing the viewpoint and then storing a list of pre-shaded, but uncolored, samples along each ray. Then, each time the RGBA transfer function is modified, the algorithm traverses the samplelists, colors the samples, and composites them along each ray until full opacity is reached. Since neither the expensive sample interpolation nor the shading are no longer necessary, we can obtain near-interactive framerates for a variety of datasets.", "year": "2002", "venue": "PG '02 Proceedings of the 10th Pacific Conference on Computer Graphics and Applications", "citations": ["539098b820f70186a0e0a6f6"], "references": [], "authors": ["Vivek Srivastava", "Uday Chebrolu", "Klaus Mueller"], "_id": {"$oid": "5797a704c60b4bee2dde33d1"}}, {"index": "5390881820f70186a0d8164b", "title": "Shear-Warp deluxe: the Shear-Warp algorithm revisited", "abstract": "Despite continued advances in volume rendering technology, the Shear-Warp algorithm, although conceived as early as 1994, still remains the world's fastest purely software-based volume rendering algorithm. The impressive speed of near double-digit framerates for moderately sized datasets, however, does come at the price of reduced image quality and memory consumption. In this paper, we present the implementation and impact of certain measures that seek to address these shortcomings. Specifically, we investigate the effects of: (i) post-interpolated classification and shading, (ii) matched volume sampling on zoom, (iii) the interpolation of intermediate slices to reduce inter-slice aliasing, and (iv) the re-use of encoded RLE runs for more than one major viewing direction to preserve memory. We also study a new variation of the shear-warp algorithm that operates on body-centered cubic grids. We find that the reduction of the number of voxels that this grid affords translates into direct savings in rendering times, with minimal degradation in image quality.", "year": "2002", "venue": "VISSYM '02 Proceedings of the symposium on Data Visualisation 2002", "citations": ["53909e7c20f70186a0e2bbd6", "5390aefc20f70186a0ece315", "5390b36120f70186a0ef1cc9", "5390b7ff20f70186a0f276b1", "5390ba3820f70186a0f36fa8", "5390893e20f70186a0d92ed7", "53908bcc20f70186a0dc5718"], "references": ["539087ae20f70186a0d4cd14", "539087c720f70186a0d56f63", "539087c720f70186a0d5842e", "539087cf20f70186a0d5cb7d", "539087cf20f70186a0d5cb7e", "539087d920f70186a0d61a63", "5390b95520f70186a0f2f6d2", "539087e720f70186a0d69475", "539087eb20f70186a0d6b605", "539087eb20f70186a0d6c076", "539087eb20f70186a0d6c0c0", "539087f320f70186a0d70fa5", "539087f820f70186a0d72a72", "5390880720f70186a0d78aee", "5390880720f70186a0d79c21", "5390880720f70186a0d79c27", "5390880720f70186a0d79c1f", "5390881720f70186a0d7fcae", "5390878720f70186a0d36057", "5390879920f70186a0d41b8b", "5390879920f70186a0d42039", "5390879920f70186a0d42033", "539088b820f70186a0d905eb", "539089ab20f70186a0d96a90", "539089ab20f70186a0d96a9f", "5390958a20f70186a0defa93"], "authors": ["Jon Sweeney", "Klaus Mueller"], "_id": {"$oid": "5797a718c60b4bee2ddf1226"}}, {"index": "539095ba20f70186a0df11f1", "title": "Volume visualization of object interiors", "abstract": "We present work on volume visualization of object interiors. Given sampled data with a segmented region of interest, the task is to efficiently and meaningfully display the density field in the interior of this region. In modern medicine, doctors are faced with this problem during each of their virtual endoscopy procedures, such as virtual bronchoscopy, virtual colonoscopy or virtual examination of blood vessels. Our work provides solutions to this problem that include automatic navigation within the region of interest and that create volume rendered views of the sampled density volume along the way. It is imperative that the views created during a virtual endoscopy are rendered as perspective projections of diagnostic quality. The perspective projection is needed to properly simulate the view of a physical endoscope. We analyze the image quality dependencies on interpolation, classification, sampling rate, and compositing buffer depth. Based on this analysis, we present algorithms and architectures to generate perspective views. The algorithms focus on generating high quality perspective projection images on general-purpose hardware with the optimal number of samples. Our volume rendering architecture supports perspective projection through an incremental slice sweep algorithm. Implemented as special-purpose hardware, it can route and process volumetric data much more efficiently than general-purpose computers and can process multiple data streams in parallel. Therefore, it can achieve much higher frame rates. For complete insight into an objects' interior all of the inner surface has to be visualized through several volume rendered views. This is enabled through our guided navigation paradigm that can smoothly transition between automatic and manual navigation of the virtual camera. For manual navigation we use a distance from boundary field to avoid collisions with the object wall. For automatic navigation we provide distance field based algorithms to compute an object's centerline and/or skeleton and then navigate the camera along the centerline or skeleton. Additionally, the automatic navigation can start anywhere inside the object, not only on the centerline or skeleton. The results of this work have been integrated into a virtual colonoscopy system that many radiologists use daily to facilitate diagnosing colon polyps in thousands of patients.", "year": "2002", "venue": "Volume visualization of object interiors", "citations": [], "references": [], "authors": ["Ingmar Bitter", "Arie E. Kaufman", "Klaus Mueller"], "_id": {"$oid": "5797a732c60b4bee2de045e2"}}, {"index": "5390882d20f70186a0d8dec0", "title": "Transferring color to greyscale images", "abstract": "We introduce a general technique for \"colorizing\" greyscale images by transferring color between a source, color image and a destination, greyscale image. Although the general problem of adding chromatic values to a greyscale image has no exact, objective solution, the current approach attempts to provide a method to help minimize the amount of human labor required for this task. Rather than choosing RGB colors from a palette to color individual components, we transfer the entire color \"mood\" of the source to the target image by matching luminance and texture information between the images. We choose to transfer only chromatic information and retain the original luminance values of the target image. Further, the procedure is enhanced by allowing the user to match areas of the two images with rectangular swatches. We show that this simple technique can be successfully applied to a variety of images and video, provided that texture and luminance are sufficiently distinct. The images generated demonstrate the potential and utility of our technique in a diverse set of application domains.", "year": "2002", "venue": "Proceedings of the 29th annual conference on Computer graphics and interactive techniques", "citations": ["5390972920f70186a0dfbaa9", "5390975920f70186a0dfc5cb", "5390979920f70186a0dfef05", "5390979920f70186a0e00d1d", "5390981d20f70186a0e04f38", "5390985e20f70186a0e09336", "539098dd20f70186a0e0eafd", "5390990f20f70186a0e0eeed", "5390990f20f70186a0e1158b", "5390994d20f70186a0e14078", "5390995d20f70186a0e14f0a", "539099a220f70186a0e177b2", "539099a220f70186a0e17e90", "539099a220f70186a0e17ed4", "539099b320f70186a0e1b696", "539099ec20f70186a0e1e36c", "53909a0220f70186a0e1f08a", "53909a0220f70186a0e2036b", "53909a0320f70186a0e20e0b", "53909e8a20f70186a0e2cb3f", "53909e8a20f70186a0e2d33c", "53909ed120f70186a0e31382", "53909eef20f70186a0e361ff", "53909f2d20f70186a0e3812b", "53909f2d20f70186a0e3873d", "53909f6920f70186a0e39bdc", "5390a01420f70186a0e48031", "5390a0b720f70186a0e4e521", "5390a17720f70186a0e53aca", "5390a1d420f70186a0e5894e", "5390a30b20f70186a0e68afc", "5390a37f20f70186a0e6d550", "5390a4cc20f70186a0e74a5b", "5390a5dc20f70186a0e7e95b", "5390a5dc20f70186a0e7ecfa", "5390a74f20f70186a0e8c18a", "5390a7f520f70186a0e92f95", "5390a7f620f70186a0e947b0", "5390a80f20f70186a0e96fba", "5390a8dc20f70186a0e9e26d", "5390a8dc20f70186a0e9ed36", "5390a93b20f70186a0ea1c48", "5390aa7620f70186a0eac153", "5390aaf920f70186a0ead1d8", "5390aaf920f70186a0eae487", "5390aaf920f70186a0eae5ab", "5390ab8820f70186a0eb00e3", "5390aca820f70186a0eb77c9", "5390aca920f70186a0eb942a", "5390ae2e20f70186a0ec896b", "5390aeba20f70186a0ecb813", "5390b0ca20f70186a0edb592", "5390b19020f70186a0edf8d8", "5390b24320f70186a0ee69ae", "5390b29820f70186a0ee91e6", "5390b29820f70186a0ee9f82", "5390b29820f70186a0eea6c9", "5390b2d720f70186a0eec92f", "5390b2fc20f70186a0eeed49", "5390b36120f70186a0ef2302", "5390b36120f70186a0ef230b", "5390b3da20f70186a0ef5ec6", "5390b3da20f70186a0ef6715", "5390b44620f70186a0ef947c", "5390b48420f70186a0efb6f9", "5390b48420f70186a0efbc80", "5390b48420f70186a0efc862", "5390b4c420f70186a0efed1a", "5390b4c420f70186a0efeda8", "5390b5ed20f70186a0f0c17a", "5390b64020f70186a0f19510", "5390b71120f70186a0f1ee3d", "5390b7fe20f70186a0f26e92", "5390b7fe20f70186a0f26e90", "5390b7fe20f70186a0f2757d", "5390b7ff20f70186a0f276a5", "5390b7ff20f70186a0f2761f", "5390b7ff20f70186a0f27781", "5390b86b20f70186a0f2965c", "5390b86b20f70186a0f29907", "5390b8d720f70186a0f2b3b0", "5390b8d720f70186a0f2c1f3", "5390b8d720f70186a0f2c1ed", "5390b8d720f70186a0f2c69d", "5390b9d520f70186a0f30f0d", "5390ba0a20f70186a0f32990", "5390ba0a20f70186a0f34478", "5390ba3820f70186a0f36fa7", "5390baa120f70186a0f37a9b", "5390bb1d20f70186a0f3d007", "5390bd1520f70186a0f43160", "5390bed320f70186a0f4d8a0", "5390bed320f70186a0f4d8a2", "5390bf1320f70186a0f516e2", "5390bf1320f70186a0f51e57", "5390bfa220f70186a0f54998", "558b0e4c612c41e6b9d41b41", "558aff29612c41e6b9d3fd56", "55323beb45cec66b6f9dade0", "53908bcc20f70186a0dc5710", "53908e0020f70186a0dd49e4", "539096cb20f70186a0df6f19", "539096cb20f70186a0df7706"], "references": ["539087a520f70186a0d490ed", "5390877f20f70186a0d312f0", "5390881720f70186a0d7fc1e", "539089ab20f70186a0d96a9c", "539089bb20f70186a0d990e1", "53908bfb20f70186a0dcacc3"], "authors": ["Tomihisa Welsh", "Michael Ashikhmin", "Klaus Mueller"], "_id": {"$oid": "5797a792c60b4bee2de4e6df"}}, {"index": "539089ab20f70186a0d96b45", "title": "Simulating fire with texture splats", "abstract": "We propose the use of textured splats as the basic display primitives for an open surface fire model. The high-detail textures help to achieve a smooth boundary of the fire and gain the small-scale turbulence appearance. We utilize the Lattice Boltzmann Model (LBM) to simulate physically-based equations describing the fire evolution and its interaction with the environment (e.g., obstacles, wind and temperature). The property of fuel and non-burning objects are defined on the lattice of the computation domain. A temperature field is also incorporated to model the generation of smoke from the fire due to incomplete combustion. The linear and local characteristics of the LBM enable us to accelerate the computation with graphics hardware to reach real-time simulation speed, while the texture splat primitives enable interactive rendering frame rates.", "year": "2002", "venue": "Proceedings of the conference on Visualization '02", "citations": ["5390975920f70186a0dfe3ad", "5390979920f70186a0dff29b", "5390979920f70186a0e00569", "5390981d20f70186a0e05850", "539098b820f70186a0e0a6da", "5390990f20f70186a0e1070f", "539099a220f70186a0e18199", "539099b320f70186a0e1a04a", "53909f2d20f70186a0e37c2a", "53909f2d20f70186a0e37c2e", "5390a06e20f70186a0e4c432", "5390b19020f70186a0edf8ea", "5390b44620f70186a0ef8be0", "5390b7fe20f70186a0f26eff", "5390b7ff20f70186a0f27767", "5390b86b20f70186a0f2811e", "53908bcc20f70186a0dc5711", "53908bfb20f70186a0dc9a85", "539095bb20f70186a0df285d"], "references": ["539087cf20f70186a0d5cbd7", "539087e120f70186a0d6586d", "539087f320f70186a0d70f96", "539087fe20f70186a0d73df3", "5390880220f70186a0d77f55", "5390881720f70186a0d7fbfa", "5390881720f70186a0d7fbfb", "5390882d20f70186a0d8def6", "5390879920f70186a0d41b8b", "53908b4920f70186a0dbc776", "53908b6c20f70186a0dbd348", "53908b9320f70186a0dc14e7", "5390958a20f70186a0def783", "5390879220f70186a0d3c872"], "authors": ["Xiaoming Wei", "Wei Li", "Klaus Mueller", "Arie Kaufman"], "_id": {"$oid": "5797a895c60b4bee2df175a1"}}, {"index": "5390893e20f70186a0d92ed7", "title": "Space-time points: 4d splatting on efficient grids", "abstract": "4D datasets, such as time-varying datasets, usually come on 4D Cartesian Cubic (CC) grids. In this paper, we explore the use of 4D Body Centered Cubic (BCC) grids to provide a more efficient sampling lattice. We use this lattice in conjunction with a point-based renderer that further reduces the data into an RLE-encoded list of relevant points. We achieve compression ranging from 50 to 80% in our experiments. Our 4D visualization approach follows the hyperslice paradigm: the user first specifies a 4D slice to extract a 3D volume, which is then viewed using a regular point-based full volume renderer. The slicing of a 4D BCC volume yields a 3D BCC volume, which theoretically has 70% of the datapoints of an equivalent CC volume. We reach compressions close to this in practice. The visual quality of the rendered BCC volume is virtually identical with that obtained from the equivalent CC volume, at 70-80% of the CC grid rendering time. Finally, we also describe a 3.5D visualization approach that uses motion blur to indicate the transition of objects along the dimension orthogonal to the extracted hyperslice in one still image. Our approach uses interleaved rendering of a motion volume and the current iso-surface volume to add the motion blurring effect with proper occlusion and depth relationships.", "year": "2002", "venue": "VVS '02 Proceedings of the 2002 IEEE symposium on Volume visualization and graphics", "citations": ["5390979920f70186a0e00559", "5390979920f70186a0e00537", "539098b820f70186a0e0a6ee", "53909e7c20f70186a0e2bbd6", "53909f8c20f70186a0e3f76b", "5390b86b20f70186a0f280f9", "5390b86b20f70186a0f28155", "5390b86b20f70186a0f2815f", "53908bcc20f70186a0dc570e", "5390958920f70186a0def081"], "references": ["539087a520f70186a0d491f2", "539087c720f70186a0d56f63", "539087c720f70186a0d5842e", "539087eb20f70186a0d6b605", "539087eb20f70186a0d6c069", "539087eb20f70186a0d6c06b", "539087eb20f70186a0d6c0c0", "539087f320f70186a0d70fa5", "539087f820f70186a0d72a39", "539087f820f70186a0d72a73", "539087f820f70186a0d72a72", "5390880720f70186a0d78aee", "5390880720f70186a0d79c27", "5390880720f70186a0d79c1f", "5390881220f70186a0d7e185", "5390881720f70186a0d7fcae", "5390878720f70186a0d34c36", "5390878720f70186a0d36057", "5390881820f70186a0d8164b", "539088b820f70186a0d905eb", "5390879920f70186a0d41b8b", "5390879920f70186a0d42039", "5390879920f70186a0d42033", "539089ab20f70186a0d96aa6", "539089ab20f70186a0d96a90", "539089ab20f70186a0d96ab1", "539089bb20f70186a0d9883c", "539089bb20f70186a0d98838", "539089bb20f70186a0d98870", "539089bb20f70186a0d98e27", "53908bcc20f70186a0dc6cec", "5390958a20f70186a0def682", "5390958a20f70186a0def6eb", "5390958a20f70186a0def77b", "5390958a20f70186a0defa93", "5390958a20f70186a0defa9d"], "authors": ["Neophytos Neophytou", "Klaus Mueller"], "_id": {"$oid": "5797a8a9c60b4bee2df27c3c"}}, {"index": "5390893e20f70186a0d92ecb", "title": "Proceedings of the 2002 IEEE symposium on Volume visualization and graphics", "abstract": "We are pleased to welcome you to the 2002 Symposium on Volume Visualization and Graphics in Boston, Massachusetts. The current event marks the seventh installment of the symposium since the 1989 Workshop at Chapel Hill, North Carolina. The VolVis Symposium has been held biannually in conjunction with the IEEE Visualization Conference since 1990. The VolVis Symposium is sponsored by the IEEE Computer Society Technical Committee on Computer Graphics in cooperation with ACM SIGGRAPH and represents one of the leading meeting forums in the domains of volume rendering, volume modeling, and vol-ume visualization. The VolVis Symposium proceedings have emerged as a major publication of state-of-the-art volume visual-ization research. We are please that, for the first time in the history of the VolVis Symposium, this year's proceedings have been printed in full-color on high-quality paper.Keynote EventThis year's keynote speaker is Ken Perlin, Professor of Computer Science at New York University and Director of the New York University Media Research Laboratory and Center for Advanced Technology. An abstract of his presentation \"Procedurally Generated Volumes\" appears in these proceedings.PapersOur call for papers yielded 36 high quality paper submissions. These were reviewed by a field of expert reviewers, composed of the Program Committee and a number of external domain experts. We wish to thank all the reviewers for their critical paper evaluations and their many suggestions for improvements. Their dedicated assistance was instrumental in the hard task to select the 16 top papers you find in these proceedings. These papers span a wide gamut of volume visualization research, such as the rendering of unstructured and structured grids as well as time-varying volumes, texture-mapping hardware accelerated rendering, rendering with haptic feedback, and volume reconstruction and triangulation.DVD ProceedingsThe proceedings this year are accompanied by a DVD-ROM that contains electronic versions of the papers as well as submitted animations.", "year": "2002", "venue": "VolVis'02 Symposium on Volume, Visualization and Graphics", "citations": [], "references": [], "authors": ["Roger Crawfis", "Chris Johnson", "Klaus Mueller"], "_id": {"$oid": "5797a8f7c60b4bee2df672d2"}}, {"index": "53908b4920f70186a0dbb89d", "title": "Post-convolved splatting", "abstract": "One of the most expensive operations in volume rendering is the interpolation of samples in volume space. The number of samples, in turn, depends on the resolution of the final image. Hence, viewing the volume at high magnification will incur heavy computation. In this paper, we explore an approach that limits the number of samples to the resolution of the volume, independent of the magnification factor, using a cheap post-convolution process on the interpolated samples to generate the missing samples. For X-ray, this post-convolution is needed only once, after the volume is fully projected, while in full volume rendering, the post-convolution must be applied before each shading and compositing step. Using this technique, we are able to achieve speedups of two and more, without compromising rendering quality. We demonstrate our approach using an image-aligned sheet-buffered splatting algorithm, but our conclusions readily generalize to any volume rendering algorithm that advances across the volume in a slice-based fashion.", "year": "2003", "venue": "VISSYM '03 Proceedings of the symposium on Data visualisation 2003", "citations": ["5390979920f70186a0e0052d", "5390b86b20f70186a0f28155"], "references": [], "authors": ["Neophytos Neophytou", "Klaus Mueller"], "_id": {"$oid": "5797a539c60b4bede9e7d1d7"}}, {"index": "539098b820f70186a0e0a6e0", "title": "Empty Space Skipping and Occlusion Clipping for Texture-based Volume Rendering", "abstract": "We propose methods to accelerate texture-based volume rendering by skipping invisible voxels. We partition the volume into sub-volumes, each containing voxels with similar properties. Sub-volumes composed of only voxels mapped to empty by the transfer function are skipped. To render the adaptively partitioned sub-volumes in visibility order, we reorganize them into an orthogonal BSP tree. We also present an algorithm that computes incrementally the intersection of the volume with the slicing planes, which avoids the overhead of the intersection and texture coordinates computation introduced by the partitioning. Rendering with empty space skipping is 2 to 5 times faster than without it. To skip occluded voxels, we introduce the concept of orthogonal opacity map, that simplifies the transformation between the volume coordinates and the opacity map coordinates, which is intensively used for occlusion detection. The map is updated efficiently by the GPU. The sub-volumes are then culled and clipped against the opacity map. We also present a method that adaptively adjusts the optimal number of the opacity map updates. With occlusion clipping, about 60% of non-empty voxels can be skipped and an additional 80% speedup on average is gained for iso-surface-like rendering.", "year": "2003", "venue": "Proceedings of the 14th IEEE Visualization 2003 (VIS'03)", "citations": ["5390979920f70186a0e0119c", "53909a9320f70186a0e21aa0", "5390a01420f70186a0e47ddf", "5390a30b20f70186a0e69775", "5390a37f20f70186a0e6d168", "5390a63c20f70186a0e8319f", "5390b00c20f70186a0ed5305", "5390b04120f70186a0ed89a3", "5390b0ca20f70186a0edb68e", "5390b3ae20f70186a0ef48b3", "5390b3ae20f70186a0ef4dd7", "5390b72d20f70186a0f2038d", "5390b7ff20f70186a0f27744", "5390b7ff20f70186a0f27ccf", "5390b86b20f70186a0f28156", "5390b86b20f70186a0f28154", "5390b86b20f70186a0f28143", "5390b86b20f70186a0f28120"], "references": ["5390879220f70186a0d3d937", "539087b320f70186a0d51108", "539087c720f70186a0d56f63", "539087cb20f70186a0d59e80", "539087d920f70186a0d6092b", "539087d920f70186a0d60c8a", "539087e120f70186a0d65836", "539087f820f70186a0d72a71", "5390880720f70186a0d78aee", "5390881720f70186a0d7fcae", "5390893e20f70186a0d92ed9", "539089ab20f70186a0d96aa5", "539089ab20f70186a0d96b42", "539089bb20f70186a0d988ba", "539089bb20f70186a0d98870", "53908a4020f70186a0d9d8a8", "53908b6c20f70186a0dbd34c", "5390958a20f70186a0def6e2", "539098b820f70186a0e0a6dc"], "authors": ["Wei Li", "Klaus Mueller", "Arie Kaufman"], "_id": {"$oid": "5797a59fc60b4bede9ebcc5a"}}, {"index": "539098b820f70186a0e0a6ee", "title": "A Frequency-Sensitive Point Hierarchy for Images and Volumes", "abstract": "This paper introduces a method for converting an image or volume sampled on a regular grid into a space-efficient irregular point hierarchy. The conversion process retains the original frequency characteristics of the dataset by matching the spatial distribution of sample points with the required frequency. To achieve good blending, the spherical points commonly used in volume rendering are generalized to ellipsoidal point primitives. A family of multiresolution, oriented Gabor wavelets provide the frequency-space analysis of the dataset. The outcome of this frequency analysis is the reduced set of points, in which the sampling rate is decreased in originally oversampled areas. During rendering, the traversal of the hierarchy can be controlled by any suitable error metric or quality criteria. The local level of refinement is also sensitive to the transfer function. Areas with density ranges mapped to high transfer function variability are rendered at higher point resolution than others. Our decomposition is flexible and can be used for iso-surface rendering, alpha compositing and X-ray rendering of volumes. We demonstrate our hierarchy with an interactive splatting volume renderer, in which the traversal of the point hierarchy for rendering is modulated by a user-specified frame rate.", "year": "2003", "venue": "Proceedings of the 14th IEEE Visualization 2003 (VIS'03)", "citations": ["5390979920f70186a0e0052d", "5390981d20f70186a0e05b7b", "539099ec20f70186a0e1c5a8", "5390b7ff20f70186a0f27713", "5390b95520f70186a0f2f791"], "references": ["5390879920f70186a0d41b8b", "539087a120f70186a0d4748f", "539087c720f70186a0d58421", "539087c720f70186a0d58425", "539087cb20f70186a0d5a879", "539087d920f70186a0d6094f", "539087e120f70186a0d65872", "539087fe20f70186a0d74a0a", "5390880220f70186a0d77fd9", "5390880720f70186a0d79c21", "5390881720f70186a0d7fc22", "5390893e20f70186a0d927fc", "5390893e20f70186a0d92ed0", "5390893e20f70186a0d92ed7", "539089ab20f70186a0d96a8a", "539089ab20f70186a0d96a89", "539089ab20f70186a0d96a90", "539089ab20f70186a0d96a88", "539089ab20f70186a0d96b42", "539089ab20f70186a0d96b2f", "539089ab20f70186a0d96b3c", "539089bb20f70186a0d9889f", "539089bb20f70186a0d98870", "539089bb20f70186a0d990e5", "53908d6520f70186a0dd283d"], "authors": ["Tomihisa Welsh", "Klaus Mueller"], "_id": {"$oid": "5797a59fc60b4bede9ebcc75"}}, {"index": "53908b4920f70186a0dbb89d", "title": "Post-convolved splatting", "abstract": "One of the most expensive operations in volume rendering is the interpolation of samples in volume space. The number of samples, in turn, depends on the resolution of the final image. Hence, viewing the volume at high magnification will incur heavy computation. In this paper, we explore an approach that limits the number of samples to the resolution of the volume, independent of the magnification factor, using a cheap post-convolution process on the interpolated samples to generate the missing samples. For X-ray, this post-convolution is needed only once, after the volume is fully projected, while in full volume rendering, the post-convolution must be applied before each shading and compositing step. Using this technique, we are able to achieve speedups of two and more, without compromising rendering quality. We demonstrate our approach using an image-aligned sheet-buffered splatting algorithm, but our conclusions readily generalize to any volume rendering algorithm that advances across the volume in a slice-based fashion.", "year": "2003", "venue": "VISSYM '03 Proceedings of the symposium on Data visualisation 2003", "citations": ["5390979920f70186a0e0052d", "5390b86b20f70186a0f28155"], "references": [], "authors": ["Neophytos Neophytou", "Klaus Mueller"], "_id": {"$oid": "5797a620c60b4bee2dd329ea"}}, {"index": "539098b820f70186a0e0a6e0", "title": "Empty Space Skipping and Occlusion Clipping for Texture-based Volume Rendering", "abstract": "We propose methods to accelerate texture-based volume rendering by skipping invisible voxels. We partition the volume into sub-volumes, each containing voxels with similar properties. Sub-volumes composed of only voxels mapped to empty by the transfer function are skipped. To render the adaptively partitioned sub-volumes in visibility order, we reorganize them into an orthogonal BSP tree. We also present an algorithm that computes incrementally the intersection of the volume with the slicing planes, which avoids the overhead of the intersection and texture coordinates computation introduced by the partitioning. Rendering with empty space skipping is 2 to 5 times faster than without it. To skip occluded voxels, we introduce the concept of orthogonal opacity map, that simplifies the transformation between the volume coordinates and the opacity map coordinates, which is intensively used for occlusion detection. The map is updated efficiently by the GPU. The sub-volumes are then culled and clipped against the opacity map. We also present a method that adaptively adjusts the optimal number of the opacity map updates. With occlusion clipping, about 60% of non-empty voxels can be skipped and an additional 80% speedup on average is gained for iso-surface-like rendering.", "year": "2003", "venue": "Proceedings of the 14th IEEE Visualization 2003 (VIS'03)", "citations": ["5390979920f70186a0e0119c", "53909a9320f70186a0e21aa0", "5390a01420f70186a0e47ddf", "5390a30b20f70186a0e69775", "5390a37f20f70186a0e6d168", "5390a63c20f70186a0e8319f", "5390b00c20f70186a0ed5305", "5390b04120f70186a0ed89a3", "5390b0ca20f70186a0edb68e", "5390b3ae20f70186a0ef48b3", "5390b3ae20f70186a0ef4dd7", "5390b72d20f70186a0f2038d", "5390b7ff20f70186a0f27744", "5390b7ff20f70186a0f27ccf", "5390b86b20f70186a0f28156", "5390b86b20f70186a0f28154", "5390b86b20f70186a0f28143", "5390b86b20f70186a0f28120"], "references": ["5390879220f70186a0d3d937", "539087b320f70186a0d51108", "539087c720f70186a0d56f63", "539087cb20f70186a0d59e80", "539087d920f70186a0d6092b", "539087d920f70186a0d60c8a", "539087e120f70186a0d65836", "539087f820f70186a0d72a71", "5390880720f70186a0d78aee", "5390881720f70186a0d7fcae", "5390893e20f70186a0d92ed9", "539089ab20f70186a0d96aa5", "539089ab20f70186a0d96b42", "539089bb20f70186a0d988ba", "539089bb20f70186a0d98870", "53908a4020f70186a0d9d8a8", "53908b6c20f70186a0dbd34c", "5390958a20f70186a0def6e2", "539098b820f70186a0e0a6dc"], "authors": ["Wei Li", "Klaus Mueller", "Arie Kaufman"], "_id": {"$oid": "5797a66bc60b4bee2dd7246d"}}, {"index": "539098b820f70186a0e0a6ee", "title": "A Frequency-Sensitive Point Hierarchy for Images and Volumes", "abstract": "This paper introduces a method for converting an image or volume sampled on a regular grid into a space-efficient irregular point hierarchy. The conversion process retains the original frequency characteristics of the dataset by matching the spatial distribution of sample points with the required frequency. To achieve good blending, the spherical points commonly used in volume rendering are generalized to ellipsoidal point primitives. A family of multiresolution, oriented Gabor wavelets provide the frequency-space analysis of the dataset. The outcome of this frequency analysis is the reduced set of points, in which the sampling rate is decreased in originally oversampled areas. During rendering, the traversal of the hierarchy can be controlled by any suitable error metric or quality criteria. The local level of refinement is also sensitive to the transfer function. Areas with density ranges mapped to high transfer function variability are rendered at higher point resolution than others. Our decomposition is flexible and can be used for iso-surface rendering, alpha compositing and X-ray rendering of volumes. We demonstrate our hierarchy with an interactive splatting volume renderer, in which the traversal of the point hierarchy for rendering is modulated by a user-specified frame rate.", "year": "2003", "venue": "Proceedings of the 14th IEEE Visualization 2003 (VIS'03)", "citations": ["5390979920f70186a0e0052d", "5390981d20f70186a0e05b7b", "539099ec20f70186a0e1c5a8", "5390b7ff20f70186a0f27713", "5390b95520f70186a0f2f791"], "references": ["5390879920f70186a0d41b8b", "539087a120f70186a0d4748f", "539087c720f70186a0d58421", "539087c720f70186a0d58425", "539087cb20f70186a0d5a879", "539087d920f70186a0d6094f", "539087e120f70186a0d65872", "539087fe20f70186a0d74a0a", "5390880220f70186a0d77fd9", "5390880720f70186a0d79c21", "5390881720f70186a0d7fc22", "5390893e20f70186a0d927fc", "5390893e20f70186a0d92ed0", "5390893e20f70186a0d92ed7", "539089ab20f70186a0d96a8a", "539089ab20f70186a0d96a89", "539089ab20f70186a0d96a90", "539089ab20f70186a0d96a88", "539089ab20f70186a0d96b42", "539089ab20f70186a0d96b2f", "539089ab20f70186a0d96b3c", "539089bb20f70186a0d9889f", "539089bb20f70186a0d98870", "539089bb20f70186a0d990e5", "53908d6520f70186a0dd283d"], "authors": ["Tomihisa Welsh", "Klaus Mueller"], "_id": {"$oid": "5797a66bc60b4bee2dd72488"}}, {"index": "53908b4920f70186a0dbba1d", "title": "Development of NPACI Grid Application Portals and Portal Web Services", "abstract": "Grid portals and services are emerging as convenient mechanisms for providing the scientific community with familiar and simplified interfaces to the Grid. Our experiences in implementing computational grid portals, and the services needed to support them, has led to the creation of GridPort: a unique, integrated, layered software system for building portals and hosting portal services that access Grid services. The usefulness of this system has been successfully demonstrated with the implementation of several application portals. This system has several unique features: the software is portable and runs on most webservers; written in Perl/CGI, it is easy to support and modify; a single API provides access to a host of Grid services; it is flexible and adaptable; it supports single login between multiple portals; and portals built with it may run across multiple sites and organizations. In this paper we summarize our experiences in building this system, including philosophy and design choices and we describe the software we are building that support portal development, portal services. Finally, we discuss our experiences in developing the GridPort Client Toolkit in support of remote Web client portals and Grid Web services.", "year": "2003", "venue": "Cluster Computing", "citations": [], "references": [], "authors": ["M. Thomas", "J. Boisseau", "M. Dahan", "C. Mills", "S. Mock", "K. Mueller"], "_id": {"$oid": "5797a68ec60b4bee2dd8d946"}}, {"index": "539099ec20f70186a0e1e2d4", "title": "Multi-texture modeling of 3D traffic scenes", "abstract": "We present a system for 3D reconstruction of traffic scenes. Traffic surveillance is a challenging scenario for 3D reconstruction in cases, where only a small number of views is available that do not contain much overlap. We address the possibilities and restrictions for modeling such scenarios with only a few cameras and introduce a compositor that allows rendering of the semi automatically generated 3D scenes. Some of the occurring problems concern camera images, which might show a common background area, but can still differ drastically in lighting effects. For foreground objects nearly no common visual information might be available, as angles between cameras may exceed even 90/spl deg/.", "year": "2003", "venue": "ICME '03 Proceedings of the 2003 International Conference on Multimedia and Expo - Volume 2", "citations": ["5390a25820f70186a0e5f97d", "5390a7f620f70186a0e95155", "5390b13020f70186a0eddea4", "5390be6620f70186a0f4d0c3"], "references": ["539087b320f70186a0d513f6", "539087d920f70186a0d60c83", "539087e120f70186a0d66da0", "5390880220f70186a0d76ce3", "53908f5b20f70186a0dd9a81"], "authors": ["K. Mueller", "A. Smolic", "M. Droese", "P. Voigt", "T. Wienand"], "_id": {"$oid": "5797a761c60b4bee2de274a9"}}, {"index": "53908bcc20f70186a0dc5711", "title": "Volumetric ablation rendering", "abstract": "In this paper, we propose a physically-based method for simulating the process of ablation on volumetric models. We demonstrate the visual effect of ablative processes, such as a beam of heat emitted from a blow torch or a pencil of sand expelled from a sandblaster. Users are able to control ablative properties, such as energy propagation, absorption, and material evaporation, via a simple transfer function interface, while the effect of different beam shapes can be modeled by ways of weighting functions.Continuous evaporation of material to expose interior object features can eliminate smooth object boundary layers required for good gradient estimation. To prevent this adverse effect, our method leaves the original volume intact and instead operates on a smooth energy volume. The renderer then uses the energy volume to determine the current, smooth object boundaries, for the opacity and gradient calculations, while the original volume provides the visual material properties, such as color and shading coefficients.", "year": "2003", "venue": "VG '03 Proceedings of the 2003 Eurographics/IEEE TVCG Workshop on Volume graphics", "citations": ["5390a06e20f70186a0e4c432", "5390a17720f70186a0e52127", "5390ad8920f70186a0ebf566", "5390b7fe20f70186a0f26f04", "559006da0cf2351542719043"], "references": ["539087a120f70186a0d4748e", "539087b320f70186a0d51117", "5390b86b20f70186a0f28128", "539087eb20f70186a0d6c04e", "539087eb20f70186a0d6c06e", "539087f320f70186a0d70fa2", "5390880220f70186a0d77fb4", "5390880720f70186a0d78aee", "5390881720f70186a0d7fbfe", "5390881720f70186a0d7fcae", "5390878720f70186a0d36057", "5390882420f70186a0d89432", "539088b820f70186a0d8f3d6", "539089ab20f70186a0d96b45", "53908b6c20f70186a0dbf640", "5390879920f70186a0d41b8b", "53908bde20f70186a0dc740d"], "authors": ["Hari Varadhan", "Klaus Mueller"], "_id": {"$oid": "5797a7a7c60b4bee2de5ea1d"}}, {"index": "53908bcc20f70186a0dc570c", "title": "Proceedings of the 2003 Eurographics/IEEE TVCG Workshop on Volume graphics", "abstract": "These are the Volume Graphics 2003 (VG'03) Workshop Proceedings. This workshop, held in Tokyo, Japan, on July 7-8, 2003, was organized as a follow-up to the very successful biennial international workshops on volume graphics, which were held in Swansea, UK (1999) and Stony Brook, New York, USA (2001). The Volume Graphics workshop series and its conjugate, the Volume Visualization and Graphics Symposium series, take place in alternate years to jointly serve as the leading forums for presenting the state-of-the-art and forecasting future trends in volumetric imaging and its applications. VG'03 was co-scheduled with the Computer Graphics International 2003 Conference (CGI'03) in Tokyo in order to mutually benefit the two events.This VG'03 workshop is co-sponsored by the IEEE Computer Society Technical Committee on Visualization and Computer Graphics (TCVG) and the European Association for Computer Graphics (Eurographics) in coop-eration with ACM SIGGRAPH. This year the proceedings are published by ACM SIGGRAPH for the first time, making the contributions to our workshop much more visible than in past years. We would like to thank our sponsors and the members of the organization committee, especially Heinrich M\u00fcller, the Eurographics workshops board chair; Bowen Loftin, IEEE CS TCVG chair; Werner Purgathofer, the Eurographics workshop series editor; and Stephen Spencer, ACM SIGGRAPH Director for Publications.Each of the submitted papers was reviewed by four domain experts. The best 17 papers were accepted and appear in these proceedings. Thanks to the devoted assistance of the program committee members and addition-al reviewers, the accepted papers encompass all aspects of volume graphics and visualization: from modeling, representation, manipulation, rendering, to systems and applications; and constitute six plenary regular ses-sions, together with a keynote speech and a capstone address during the two full workshop days.", "year": "2003", "venue": "VG03 3rd International Workshop on Volume Graphics", "citations": [], "references": [], "authors": ["Arie Kaufman", "Issei Fujishiro", "Klaus Mueller"], "_id": {"$oid": "5797a7dec60b4bee2de7e50f"}}, {"index": "5390975920f70186a0dfcd85", "title": "3D Reconstruction of Natural Scenes with View-Adaptive Multi-Texturing", "abstract": "We present a 3D reconstruction and modeling system that operates on a number of input photographs that show a natural scene. Approaches from computer graphics and image processing are combined and performance is shown via experiments. Furthermore, reconstruction quality is analyzed w.r.t. the number and distribution of textures, used for reconstruction. The reconstruction pipeline starts with image acquisition, which consists of a number of photographs of the scene that are sequentially taken at different positions. Since the photographs are not acquired concurrently, they are influenced by different illumination conditions that we mandate to be preserved in the final 3D representation. In the second step, object segmentation is applied and camera calibration provided. This allows the application of shape-from-silhouette approaches, namely a hierarchical voxel approach, where different resolution layers are organized within an octree structure. For applying texture mapping, the voxel model is transformed into a wireframe, which provides smoothing of the object's surface and also reduces the number of surface primitives. Finally, a subset of original images is mapped onto the 3D geometry to provide texture information. Here, view-adaptive multi-texturing is used to preserve natural illumination. Intermediate views are interpolated automatically using adaptive real-time weight calculations for original textures.", "year": "2004", "venue": "3DPVT '04 Proceedings of the 3D Data Processing, Visualization, and Transmission, 2nd International Symposium", "citations": [], "references": [], "authors": ["K. Mueller", "A. Smolic", "P. Merkle", "B. Kaspar", "P. Eisert", "T. Wiegand"], "_id": {"$oid": "5797a572c60b4bede9e9f87e"}}, {"index": "5390975920f70186a0dfcd85", "title": "3D Reconstruction of Natural Scenes with View-Adaptive Multi-Texturing", "abstract": "We present a 3D reconstruction and modeling system that operates on a number of input photographs that show a natural scene. Approaches from computer graphics and image processing are combined and performance is shown via experiments. Furthermore, reconstruction quality is analyzed w.r.t. the number and distribution of textures, used for reconstruction. The reconstruction pipeline starts with image acquisition, which consists of a number of photographs of the scene that are sequentially taken at different positions. Since the photographs are not acquired concurrently, they are influenced by different illumination conditions that we mandate to be preserved in the final 3D representation. In the second step, object segmentation is applied and camera calibration provided. This allows the application of shape-from-silhouette approaches, namely a hierarchical voxel approach, where different resolution layers are organized within an octree structure. For applying texture mapping, the voxel model is transformed into a wireframe, which provides smoothing of the object's surface and also reduces the number of surface primitives. Finally, a subset of original images is mapped onto the 3D geometry to provide texture information. Here, view-adaptive multi-texturing is used to preserve natural illumination. Intermediate views are interpolated automatically using adaptive real-time weight calculations for original textures.", "year": "2004", "venue": "3DPVT '04 Proceedings of the 3D Data Processing, Visualization, and Transmission, 2nd International Symposium", "citations": [], "references": [], "authors": ["K. Mueller", "A. Smolic", "P. Merkle", "B. Kaspar", "P. Eisert", "T. Wiegand"], "_id": {"$oid": "5797a648c60b4bee2dd55091"}}, {"index": "5390979920f70186a0e011a0", "title": "Feature Preserving Distance Fields", "abstract": "We present two distance field representations which can preserve sharp features in original geometric models: the offset distance field (ODF) and the unified distance field (UDF). The ODF is sampled on a special curvilinear grid named an offset grid. The sample points of the ODF are not on a regular grid and they can float in the cells of a regular base grid. The ODF can naturally adapt to curvature variations in the original mesh and can preserve sharp features. We describe an energy minimization approach to convert geometric models to ODFs. The UDF integrates multiple distance field representations into one data structure. By adaptively using different representations for different parts of a shape, the UDF can provide high fidelity surface representation with compact storage and fast rendering speed.", "year": "2004", "venue": "VV '04 Proceedings of the 2004 IEEE Symposium on Volume Visualization and Graphics", "citations": ["5390ab8820f70186a0eb1745"], "references": ["5390878720f70186a0d34653", "539087b320f70186a0d510ec", "539087dd20f70186a0d62a4c", "539087e720f70186a0d68f5f", "539087eb20f70186a0d6c049", "539087eb20f70186a0d6c04e", "539087f820f70186a0d72a6a", "5390880220f70186a0d77fb4", "5390881220f70186a0d7e186", "5390881720f70186a0d7fbff", "5390881720f70186a0d7fbfe", "5390882d20f70186a0d8dec8", "539089ab20f70186a0d96aa4", "539089bb20f70186a0d98878", "5390958a20f70186a0def6af", "539098b820f70186a0e0a6f0", "5390b5c620f70186a0f08b32"], "authors": ["Huamin Qu", "Nan Zhang", "Ran Shao", "Arie Kaufman", "Klaus Mueller"], "_id": {"$oid": "5797a722c60b4bee2ddf8129"}}, {"index": "5390981d20f70186a0e05118", "title": "Squeeze: numerical-precision-optimized volume rendering", "abstract": "This paper discusses how to squeeze volume rendering into as few bits per operation as possible while still retaining excellent image quality. For each of the typical volume rendering pipeline stages in texture map volume rendering, ray casting and splatting we provide a quantitative analysis of the theoretical and practical limits for the required bit precision for computation and storage. Applying this analysis to any volume rendering implementation can balance the internal precisions based on the desired final output precision and can result in significant speedups and reduced memory footprint.", "year": "2004", "venue": "Proceedings of the ACM SIGGRAPH/EUROGRAPHICS conference on Graphics hardware", "citations": ["5390b86b20f70186a0f28155", "5390b95520f70186a0f2f749"], "references": ["5390878720f70186a0d36057", "5390879920f70186a0d41b8b", "539087a520f70186a0d491f2", "539087c720f70186a0d56f63", "539087d920f70186a0d6092a", "539087e720f70186a0d69475", "539087eb20f70186a0d6c076", "539087eb20f70186a0d6c0be", "539087f320f70186a0d70fa5", "539087f820f70186a0d72a72", "5390880720f70186a0d78aee", "5390880720f70186a0d79c1f", "5390880720f70186a0d79c21", "5390881720f70186a0d7fcae", "539088b820f70186a0d8f3d9", "5390893e20f70186a0d92ed0", "539089ab20f70186a0d96b42", "539089bb20f70186a0d98870", "53908bad20f70186a0dc3150", "53908bcc20f70186a0dc6ccc", "5390b61e20f70186a0f14b8e"], "authors": ["Ingmar Bitter", "Neophytos Neophytou", "Klaus Mueller", "Arie E. Kaufman"], "_id": {"$oid": "5797a743c60b4bee2de11eb9"}}, {"index": "539098b820f70186a0e0ba72", "title": "Ray based exploration of volumetric data", "abstract": "In this work we present techniques for the exploration of three dimensional (3D) volumetric data that provide a key to the understanding of data. Today, physicians and scientists have access to advanced scanning modalities such as computed tomography (CT) and magnetic resonance imaging (MRI) that produce complex high resolution volumetric datasets. In order to make a timely diagnosis, physicians need to quickly explore this large amount of data. The exploration techniques presented in this work assist the physicians in making a diagnosis and scientists in comprehending the data. Our model for the exploration of 3D volumetric data has two steps: the segmentation of the region of interest and its visualization. The segmentation and visualization techniques presented use a ray-based approach, where the data is analyzed and processed along a ray. We present three algorithms for segmentation that overcome the commonly encountered problem of partial volume effect. In one of the algorithms, we present segmentation rays that are special purpose rays designed to detect and optionally remove partial volume effect. Removing partial volume avoids obstruction of the region of interest when the data is visualized. For visualizing segmented volumetric data we present a new paradigm of volumetric extraction. This technique can be used to either extract the region of interest or to remove unwanted regions from the data. Our extraction technique works in such a way that it maintains the smooth transition at object boundaries. This smooth transition allows high quality visualization of the region of interest using direct volume rendering. For rendering volumetric data, we present a new direct volume rendering technique that compensates for partial volume and avoids miss-classification and miss-coloring of partial volume voxels. Our technique presents a very simple transfer function interface to the user, avoiding the complexities of multi-dimensional transfer functions. We further present a new paradigm in visualization that combines segmentation and classification during volume rendering. Unlike traditional volume rendering where an object's surface is displayed, our technique scans the object interior and displays classification information on the surface in different colors. We use a ray-based technique similar to the segmentation rays introduced earlier, to perform segmentation and classification on the object interior. We show the usefulness of our technique for the computer-aided detection of potential cancerous growth inside the colon. An important requirement for effective exploration of data is interactivity. We present an acceleration technique for direct volume rendering that uses ray-coherence to space leap rays when they traverse through transparent regions.", "year": "2004", "venue": "Ray based exploration of volumetric data", "citations": [], "references": [], "authors": ["Arie Kaufman", "Klaus Mueller", "Sarang Avinash Lakare"], "_id": {"$oid": "5797a7dfc60b4bee2de7f741"}}, {"index": "5390b86b20f70186a0f280d9", "title": "Point-based surface rendering with motion blur", "abstract": "In this paper we show how to extend point-based surface rendering to illustrate object motion. We do this by first extruding the circular points into ellipsoids, which fill the space traced out by the points in motion. Using ellipsoids instead of cylinders achieves a low-passing effect of the motion trail. We then find the screen-space projection of each ellipsoid, which is an ellipse. These can be rendered conveniently using hardware acceleration. Our technique thus facilitates the rendering of complex objects with real-time motion blur. It gives the viewer a sharply rendered object together with the hint of the direction of motion. The construction of the motion blur trails can be based on different rendering primitives, as is also discussed in the paper. Various trail textures are presented to achieve artistic rendering results.", "year": "2004", "venue": "SPBG'04 Proceedings of the First Eurographics conference on Point-Based Graphics", "citations": ["5390ad8920f70186a0ebf560", "5390b7fe20f70186a0f26f08", "5390b7ff20f70186a0f278be"], "references": ["539087a120f70186a0d45206", "539087b320f70186a0d5110f", "539087b320f70186a0d5110e", "5390877920f70186a0d2e230", "5390878720f70186a0d3464b", "5390879920f70186a0d41b85", "539087eb20f70186a0d6c0c0", "539087fe20f70186a0d73dc6", "539087fe20f70186a0d73dcb", "539087fe20f70186a0d73dc9", "539087fe20f70186a0d73dcd", "5390880220f70186a0d77fd5", "5390880220f70186a0d77fd9", "5390881720f70186a0d7fc22", "539089bb20f70186a0d987f7", "539089bb20f70186a0d98858", "539089bb20f70186a0d988c5", "539089bb20f70186a0d988cb", "539089bb20f70186a0d98e9b", "53908b9320f70186a0dc14e9", "53908b9320f70186a0dc153c", "53908b9320f70186a0dc14e7", "53908b9320f70186a0dc14e8", "53908bad20f70186a0dc3148", "53908bad20f70186a0dc314c"], "authors": ["Xin Guan", "Klaus Mueller"], "_id": {"$oid": "5797a829c60b4bee2debc500"}}, {"index": "5390979920f70186a0e0052e", "title": "Generating Sub-Resolution Detail in Images and Volumes Using Constrained Texture Synthesis", "abstract": "A common deficiency of discretized datasets is that detail beyond the resolution of the dataset has been irrecoverably lost. This lack of detail becomes immediately apparent once one attempts to zoom into the dataset and only recovers blur. Here, we describe a method that generates the missing detail from any available and plausible high-resolution data, using texture synthesis. Since the detail generation process is guided by the underlying image or volume data and is designed to fill in plausible detail in accordance with the coarse structure and properties of the zoomed-in neighborhood, we refer to our method as constrained texture synthesis. Regular zooms become \"semantic zooms\", where each level of detail stems from a data source attuned to that resolution. We demonstrate our approach by a medical application \u9a74 the visualization of a human liver \u9a74 but its principles readily apply to any scenario, as long as data at all resolutions are available. We will first present a 2D viewing application, called the \"virtual microscope\", and then extend our technique to 3D volumetric viewing.", "year": "2004", "venue": "VIS '04 Proceedings of the conference on Visualization '04", "citations": ["5390990f20f70186a0e0eedd", "53909a9320f70186a0e21a82", "5390a30b20f70186a0e6b046", "5390a72220f70186a0e8aabe", "5390aa7620f70186a0eaaac8", "5390ac1820f70186a0eb3341", "5390b78a20f70186a0f24566"], "references": ["539087b320f70186a0d510f2", "539087d420f70186a0d5df9b", "539087f320f70186a0d70fa3", "5390880220f70186a0d7801b", "5390880220f70186a0d78018", "5390881720f70186a0d7fc1e", "5390881720f70186a0d7fc1f", "5390881720f70186a0d7fc1d", "5390881720f70186a0d80359", "5390882120f70186a0d857bb", "5390882d20f70186a0d8deef", "539088b820f70186a0d900f0", "5390893e20f70186a0d92800", "539089bb20f70186a0d990fb", "5390880d20f70186a0d7bd95", "53908bfb20f70186a0dcacc3", "53908cde20f70186a0dcdb7c", "53908e0020f70186a0dd49e1", "53908e0020f70186a0dd4a5e", "53908e0020f70186a0dd49e4", "5390956e20f70186a0dec913", "539096cb20f70186a0df76e2"], "authors": ["Lujin Wang", "Klaus Mueller"], "_id": {"$oid": "5797a84fc60b4bee2dedb161"}}, {"index": "5390979920f70186a0e00525", "title": "Methods for Efficient, High Quality Volume Resampling in the Frequency Domain", "abstract": "Resampling is a frequent task in visualization and medical imaging. It occurs whenever images or volumes are magnified, rotated, translated, or warped. Resampling is also an integral procedure in the registration of multi-modal datasets, such as CT, PET, and MRI, in the correction of motion artifacts in MRI, and in the alignment of temporal volume sequences in fMRI. It is well known that the quality of the resampling result depends heavily on the quality of the interpolation filter used. However, high-quality filters are rarely employed in practice due to their large spatial extents. In this paper, we explore a new resampling technique that operates in the frequency-domain where high- quality filtering is feasible. Further, unlike previous methods of this kind, our technique is not limited to integer-ratio scaling factors, but can resample image and volume datasets at any rate. This would usually require the application of slow Discrete Fourier Transforms (DFT) to return the data to the spatial domain. We studied two methods that successfully avoid these delays: the chirp-z transform and the FFTW package. We also outline techniques to avoid the ringing artifacts that may occur with frequency-domain filtering. Thus, our method can achieve high-quality interpolation at speeds that are usually associated with spatial filters of far lower quality.", "year": "2004", "venue": "VIS '04 Proceedings of the conference on Visualization '04", "citations": ["5390b7ff20f70186a0f276c1", "5390b7ff20f70186a0f276b1", "5390b7ff20f70186a0f278d7", "5390b86b20f70186a0f28148"], "references": ["5390877f20f70186a0d2fc46", "5390879620f70186a0d4021e", "5390879920f70186a0d4203a", "539087a120f70186a0d46525", "539087dd20f70186a0d64191", "539087ef20f70186a0d6d749", "5390881220f70186a0d7ecbb", "5390881220f70186a0d7ec9d", "5390882120f70186a0d853c6", "539089bb20f70186a0d9883c", "53908bad20f70186a0dc2d7e", "5390958a20f70186a0defa93", "5390b64020f70186a0f197af", "5390b64020f70186a0f1a0ad"], "authors": ["Aili Li", "Klaus Mueller", "Thomas Ernst"], "_id": {"$oid": "5797a84fc60b4bee2dedb19c"}}, {"index": "5390979920f70186a0e00569", "title": "Dispersion Simulation and Visualization For Urban Security", "abstract": "We present a system for simulating and visualizing the propagation of dispersive contaminants with an application to urban security. In particular, we simulate airborne contaminant propagation in open environments characterized by sky-scrapers and deep urban canyons. Our approach is based on the Multiple Relaxation Time Lattice Boltzmann Model (MRTLBM), which can efficiently handle complex boundary conditions such as buildings. In addition, we model thermal effects on the flow field using the hybrid thermal MRTLBM. Our approach can also accommodate readings from various sensors distributed in the environment and adapt the simulation accordingly. We accelerate the computation and efficiently render many buildings with small textures on the GPU.We render streamlines and the contaminant smoke with self-shadowing composited with the textured buildings.", "year": "2004", "venue": "VIS '04 Proceedings of the conference on Visualization '04", "citations": ["539099ec20f70186a0e1d394", "53909a9320f70186a0e21a83", "5390a1f820f70186a0e5cec1", "5390aeba20f70186a0eca882", "5390b19020f70186a0edf8ea", "5390b7ff20f70186a0f275ca"], "references": ["5390975920f70186a0dfe3ad", "5390879920f70186a0d41b8a", "539087e120f70186a0d6586d", "539087eb20f70186a0d6a655", "539087f320f70186a0d70f96", "5390881720f70186a0d7fc1b", "5390881720f70186a0d7fbfa", "539088b820f70186a0d8f3d6", "539089ab20f70186a0d96b45", "539089ab20f70186a0d96b36", "53908b4920f70186a0dbc861", "53908bde20f70186a0dc9281", "53908bde20f70186a0dc9282", "53908bfb20f70186a0dc9a85", "53908e0020f70186a0dd4a32", "53908e0020f70186a0dd4a33", "53908e0020f70186a0dd4a12", "5390958a20f70186a0def783", "5390958a20f70186a0def922", "539095bb20f70186a0df285d", "539098b820f70186a0e0a6da", "53908e0020f70186a0dd4a1b"], "authors": ["Feng Qiu", "Ye Zhao", "Zhe Fan", "Xiaoming Wei", "Haik Lorenz", "Jianning Wang", "Suzanne Yoakum-Stover", "Arie Kaufman", "Klaus Mueller"], "_id": {"$oid": "5797a86fc60b4bee2def64ad"}}, {"index": "539095bb20f70186a0df285d", "title": "The Lattice-Boltzmann Method for Simulating Gaseous Phenomena", "abstract": "Abstract--We present a physically-based, yet fast and simple method to simulate gaseous phenomena. In our approach, the incompressible Navier-Stokes (NS) equations governing fluid motion have been modeled in a novel way to achieve a realistic animation. We introduce the Lattice Boltzmann Model (LBM), which simulates the microscopic movement of fluid particles by linear and local rules on a grid of cells so that the macroscopic averaged properties obey the desired NS equations. The LBM is defined on a 2D or 3D discrete lattice, which is used to solve fluid animation based on different boundary conditions. The LBM simulation generates, in real-time, an accurate velocity field and can incorporate an optional temperature field to account for the buoyancy force of hot gas. Because of the linear and regular operations in each local cell of the LBM grid, we implement the computation in commodity texture hardware, further improving the simulation speed. Finally, textured splats are used to add small scale turbulent details, achieving high-quality real-time rendering. Our method can also simulate the physically correct action of stationary or mobile obstacles on gaseous phenomena in real-time, while still maintaining highly plausible visual details.", "year": "2004", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["5390975920f70186a0dfe3ad", "5390979920f70186a0e00569", "539098b820f70186a0e0a6da", "5390a17720f70186a0e521e1", "5390a4cc20f70186a0e75dfa", "5390a5b020f70186a0e7d940", "5390a74f20f70186a0e8c0b4", "5390a93b20f70186a0ea1c52", "5390a9a420f70186a0ea509c", "5390ae2e20f70186a0ec921b", "5390aeba20f70186a0eca882", "5390b19020f70186a0edf8ea", "5390b7fe20f70186a0f26f06", "5390b7fe20f70186a0f2752f", "558fd7110cf2a50e8d7f0c3a", "53908bfb20f70186a0dc9a85"], "references": ["539087a120f70186a0d47472", "539087a620f70186a0d49d96", "539087b320f70186a0d51118", "539087cb20f70186a0d59724", "539087cf20f70186a0d5cbf0", "539087e120f70186a0d6586d", "539087e720f70186a0d69183", "539087ef20f70186a0d6e8db", "539087f320f70186a0d70f96", "539087fe20f70186a0d73df3", "5390880220f70186a0d76b32", "5390880220f70186a0d77f55", "5390880720f70186a0d7950e", "5390881720f70186a0d7fbfa", "539088b820f70186a0d8f3d6", "539089ab20f70186a0d96b45", "5390879220f70186a0d3c872", "53908b6c20f70186a0dbf640", "53908b9320f70186a0dc14e7", "5390958a20f70186a0def783", "5390879920f70186a0d41b8f", "5390879920f70186a0d41b8a"], "authors": ["Xiaoming Wei", "Wei Li", "Klaus Mueller", "Arie E. Kaufman"], "_id": {"$oid": "5797a880c60b4bee2df053ba"}}, {"index": "5390b3ae20f70186a0ef370e", "title": "Dynamic approach for face recognition using digital image skin correlation", "abstract": "With the recent emphasis on homeland security, there is an increased interest in accurate and non-invasive techniques for face recognition. Most of the current techniques perform a structural analysis of facial features from still images. Recently, video-based techniques have also been developed but they suffer from low image-quality. In this paper, we propose a new method for face recognition, called Digital Image Skin Correlation (DISC), which is based on dynamic instead of static facial features. DISC tracks the motion of skin pores on the face during a facial expression and obtains a vector field that characterizes the deformation of the face. Since it is almost impossible to imitate another person's facial expressions these deformation fields are bound to be unique to an individual. To test the performance of our method in face recognition scenarios, we have conducted experiments where we presented individuals wearing heavy make-up as disguise to our DISC matching framework. The results show superior face recognition performance when compared to the popular PCA+ LDA method, which is based on still images.", "year": "2005", "venue": "AVBPA'05 Proceedings of the 5th international conference on Audio- and Video-Based Biometric Person Authentication", "citations": ["5390a2be20f70186a0e64a8e", "5390aaf920f70186a0eaeb2b", "5390aca820f70186a0eb866d", "558b8e2e612c6b62e5e8b717"], "references": ["5390980720f70186a0e0251d", "53909e7c20f70186a0e2bf3e", "5390af8920f70186a0ecf59d", "539087e120f70186a0d661d8", "5390880720f70186a0d79ccf", "53908a9720f70186a0da5cce", "53908b9320f70186a0dc05e6", "5390958a20f70186a0df0383"], "authors": ["Satprem Pamudurthy", "E. Guan", "Klaus Mueller", "Miriam Rafailovich"], "_id": {"$oid": "5797a533c60b4bede9e78ec6"}}, {"index": "5390b3ae20f70186a0ef370e", "title": "Dynamic approach for face recognition using digital image skin correlation", "abstract": "With the recent emphasis on homeland security, there is an increased interest in accurate and non-invasive techniques for face recognition. Most of the current techniques perform a structural analysis of facial features from still images. Recently, video-based techniques have also been developed but they suffer from low image-quality. In this paper, we propose a new method for face recognition, called Digital Image Skin Correlation (DISC), which is based on dynamic instead of static facial features. DISC tracks the motion of skin pores on the face during a facial expression and obtains a vector field that characterizes the deformation of the face. Since it is almost impossible to imitate another person's facial expressions these deformation fields are bound to be unique to an individual. To test the performance of our method in face recognition scenarios, we have conducted experiments where we presented individuals wearing heavy make-up as disguise to our DISC matching framework. The results show superior face recognition performance when compared to the popular PCA+ LDA method, which is based on still images.", "year": "2005", "venue": "AVBPA'05 Proceedings of the 5th international conference on Audio- and Video-Based Biometric Person Authentication", "citations": ["5390a2be20f70186a0e64a8e", "5390aaf920f70186a0eaeb2b", "5390aca820f70186a0eb866d", "558b8e2e612c6b62e5e8b717"], "references": ["5390980720f70186a0e0251d", "53909e7c20f70186a0e2bf3e", "5390af8920f70186a0ecf59d", "539087e120f70186a0d661d8", "5390880720f70186a0d79ccf", "53908a9720f70186a0da5cce", "53908b9320f70186a0dc05e6", "5390958a20f70186a0df0383"], "authors": ["Satprem Pamudurthy", "E. Guan", "Klaus Mueller", "Miriam Rafailovich"], "_id": {"$oid": "5797a61bc60b4bee2dd2e6d9"}}, {"index": "5390b86b20f70186a0f28155", "title": "GPU accelerated image aligned splatting", "abstract": "Splatting is a popular technique for volume rendering, where voxels are represented by Gaussian kernels, whose pre-integrated footprints are accumulated to form the image. Splatting has been mainly used to render pre-shaded volumes, which can result in significant blurring in zoomed views. This can be avoided in the image-aligned splatting scheme, where one accumulates kernel slices into equi-distant, parallel sheet buffers, followed by classification, shading, and compositing. In this work we attempt to evolve this algorithm to the next level: GPU based acceleration. First we describe the challenges that the highly parallel \"Gather\" architecture of modern GPUs poses to the \"Scatter\" based nature of a splatting algorithm. We then describe a number of strategies that exploit newly introduced features of the latest-generation hardware to address these limitations. Two crucial operations to boost the performance in image-aligned splatting are the early elimination of hidden splats and the skipping of empty buffer-space. We will describe mechanisms which take advantage of the early z-culling hardware facilities to accomplish both of these operations efficiently in hardware.", "year": "2005", "venue": "VG'05 Proceedings of the Fourth Eurographics / IEEE VGTC conference on Volume Graphics", "citations": ["5390a63c20f70186a0e8137f", "5390a7f520f70186a0e942e6", "5390b7ff20f70186a0f278be", "5390b7ff20f70186a0f27cea", "5390bf1320f70186a0f5140e"], "references": ["5390979920f70186a0e0052d", "5390981d20f70186a0e05121", "5390981d20f70186a0e05118", "539087a120f70186a0d4748f", "5390879920f70186a0d41b8b", "539087e620f70186a0d67561", "539087eb20f70186a0d6c0c0", "539087f820f70186a0d72a72", "5390881220f70186a0d7e17e", "5390881720f70186a0d7fc22", "5390893e20f70186a0d92ed7", "539089ab20f70186a0d96a90", "539089bb20f70186a0d98858", "539089bb20f70186a0d988cb", "539089bb20f70186a0d98870", "53908b4920f70186a0dbb89d", "53908b6c20f70186a0dbd34c"], "authors": ["Neophytos Neophytou", "Klaus Mueller"], "_id": {"$oid": "5797a6d7c60b4bee2ddc40de"}}, {"index": "539098b820f70186a0e0a272", "title": "Guest Editors' Introduction: Special Section on IEEE Visualization Applications", "abstract": "", "year": "2005", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": [], "references": [], "authors": ["Eduard Groller", "Kwan-Liu Ma", "Klaus Mueller"], "_id": {"$oid": "5797a7b6c60b4bee2de68169"}}, {"index": "5390b7ff20f70186a0f276c1", "title": "Spline-based gradient filters for high-quality refraction computations in discrete datasets", "abstract": "Based on the finding that refraction imposes significantly higher demands onto gradient filters than illumination and shading, we evaluate the family of spline filters as a good alternative to the cubic filters, which so far have served as the gold standard of efficient yet high-quality interpolation filters in present visualization applications. Using a regular background texture to visualize the refractive properties of the volumetric object, we also describe an efficient scheme to achieve the effects of supersampling without incurring any extra raycasting overhead. Our results indicate that splines can be superior to the Catmull-Rom filter, with potentially less computational overhead, also offering a convenient means to adjust the extent of lowpassing and smoothing.", "year": "2005", "venue": "EUROVIS'05 Proceedings of the Seventh Joint Eurographics / IEEE VGTC conference on Visualization", "citations": ["53909e7c20f70186a0e2c0e2", "5390b86b20f70186a0f28148"], "references": ["5390979920f70186a0e00525", "5390877f20f70186a0d2fa1a", "5390b52620f70186a0f020a6", "5390b52620f70186a0f020a5", "5390b64020f70186a0f19a32", "539087eb20f70186a0d6c063", "5390880720f70186a0d7ab0a", "5390881820f70186a0d81082", "539089bb20f70186a0d9883c", "539089bb20f70186a0d98824", "539089bb20f70186a0d98877", "539089bb20f70186a0d988ce", "539089bb20f70186a0d98836", "53908bad20f70186a0dc314a", "53908bad20f70186a0dc314b", "5390958a20f70186a0defa93", "5390b86b20f70186a0f28148", "5390b86b20f70186a0f28124"], "authors": ["Shengying Li", "Klaus Mueller"], "_id": {"$oid": "5797a868c60b4bee2def0a7b"}}, {"index": "5390b86b20f70186a0f28148", "title": "Accelerated, high-quality refraction computations for volume graphics", "abstract": "We present an efficient framework for the high-quality rendering of discretely sampled surface-based objects with refractive effects. This requires an accurate estimation of the refraction coefficients, paired with efficient and accurate surface detection, space traversal, and backdrop image sampling. Our framework achieves these goals, by employing a high-quality spline-based filter in conjunction with a novel filtered octree space decomposition with pre-classified cells that is carefully matched to the filter and voxel neighborhood characteristics. Here, we benefit greatly from the non-negativity of the B-Spline kernel. Finally, we describe an innovative scheme that achieves the high quality of pixel super-sampling on a flat backdrop plane without the overhead of tracing the actual rays across the refractive object.", "year": "2005", "venue": "VG'05 Proceedings of the Fourth Eurographics / IEEE VGTC conference on Volume Graphics", "citations": ["5390990f20f70186a0e1102e", "53909e7c20f70186a0e2c0e2", "53909f8c20f70186a0e40c73", "5390b7ff20f70186a0f276c1"], "references": ["5390975920f70186a0dfc591", "5390979920f70186a0e00525", "5390877f20f70186a0d2fa1a", "5390b52620f70186a0f020a6", "5390b52620f70186a0f020a5", "5390b64020f70186a0f19a32", "5390b7ff20f70186a0f276c1", "5390b86b20f70186a0f28124", "539087eb20f70186a0d6c063", "5390880720f70186a0d7ab0a", "5390881820f70186a0d81082", "539089bb20f70186a0d9883c", "539089bb20f70186a0d98824", "539089bb20f70186a0d98877", "539089bb20f70186a0d988ce", "539089bb20f70186a0d98836", "53908bad20f70186a0dc314a", "53908bad20f70186a0dc314b", "5390958a20f70186a0defa93"], "authors": ["Shengying Li", "Klaus Mueller"], "_id": {"$oid": "5797a8d8c60b4bee2df4df9a"}}, {"index": "53909fbd20f70186a0e42776", "title": "A generalized framework for interactive volumetric point-based rendering", "abstract": "Volume Visualization is the process of displaying volumetric data represented as sample points on a regular or irregular 3D grid. The data is currently produced by medical scanners such as MRI, CT, etc, and by numerical methods such as scientific simulations. Techniques that have been proposed for this purpose over the years include direct volume-rendering which seeks to capture a visual impression of the complete 3D dataset by accounting for the emission and light absorption effects of all the data elements. This technique is effective when rendering volumes of space-filling gasses or volumes composed of many micro-surfaces, such as tissue in medical datasets. We have focused our efforts on Point-Based Volume rendering and specifically on the image-aligned post-shaded splatting algorithm which was proposed as a remedy to the drawbacks of existing algorithms with special focus on image quality. In the course of this dissertation, we will follow the evolution of this algorithm through several stages of maturity. Our contributions to this algorithm include the ability to render efficient grid topologies with significant storage and rendering time gains for both 3D as well as time-varying datasets. We have also proposed a post-convolved volume rendering technique to accelerate magnified viewing. The framework has been ported to a hardware-accelerated implementation that has the ability to interactively slice point based volumes and was optimized to take full advantage of the splatting algorithm's inherent advantages for empty-space skipping and early splat elimination. Finally, we have generalized our framework for the interactive rendering of irregular datasets consisting of ellipsoidal kernels of arbitrary size and orientation. Our suggested algorithm outperforms existing hardware approaches by about an order of magnitude in terms of throughput. Different modeling approaches have been explored for encoding the data using either RBF (Radial Basis Functions) or EBF (Elliptical Basis Functions), and new methods are proposed for ongoing/future work. The final goal is a truly general point-based hardware-accelerated framework for the interactive visualization of both regular and irregular volumetric data in high-fidelity.", "year": "2006", "venue": "A generalized framework for interactive volumetric point-based rendering", "citations": [], "references": [], "authors": ["Klaus Mueller", "Neophytos Neophytou"], "_id": {"$oid": "5797a6b3c60b4bee2ddac551"}}, {"index": "5390b7ff20f70186a0f278be", "title": "GPU-accelerated volume splatting with elliptical RBFs", "abstract": "Radial Basis Functions (RBFs) have become a popular rendering primitive, both in surface and in volume rendering. This paper focuses on volume visualization, giving rise to 3D kernels. RBFs are especially convenient for the representation of scattered and irregularly distributed point samples, where the RBF kernel is used as a blending function for the space in between samples. Common representations employ radially symmetric RBFs, and various techniques have been introduced to render these, also with efficient implementations on programmable graphics hardware (GPUs). In this paper, we extend the existing work to more generalized, ellipsoidal RBF kernels, for the rendering of scattered volume data. We devise a post-shaded kernel-centric rendering approach, specifically designed to run efficiently on GPUs, and we demonstrate our renderer using datasets from subdivision volumes and computational science.", "year": "2006", "venue": "EUROVIS'06 Proceedings of the Eighth Joint Eurographics / IEEE VGTC conference on Visualization", "citations": ["5390a7f520f70186a0e942e6", "5390b7ff20f70186a0f27713"], "references": ["5390972920f70186a0dfab36", "5390975920f70186a0dfc801", "5390975920f70186a0dfcbda", "5390979920f70186a0e0052d", "5390979920f70186a0e0055d", "5390979920f70186a0e0055b", "539098dc20f70186a0e0cc71", "5390a72220f70186a0e8aaec", "5390b7ff20f70186a0f2772a", "5390879920f70186a0d41b8b", "539087f820f70186a0d72a72", "5390880220f70186a0d77fd5", "5390880220f70186a0d77fd9", "5390881720f70186a0d7fcae", "5390881720f70186a0d8040c", "5390881820f70186a0d8164e", "539089ab20f70186a0d96a88", "539089bb20f70186a0d9881d", "539089bb20f70186a0d98870", "5390958a20f70186a0def783", "5390b86b20f70186a0f280d9", "5390b86b20f70186a0f28155"], "authors": ["Neophytos Neophytou", "Klaus Mueller", "Kevin T. McDonnell", "Wei Hong", "Xin Guan", "Hong Qin", "Arie Kaufman"], "_id": {"$oid": "5797a711c60b4bee2ddec66f"}}, {"index": "53909a0220f70186a0e1f916", "title": "Color-space CAD", "abstract": "", "year": "2006", "venue": "ACM SIGGRAPH 2006 Sketches", "citations": [], "references": [], "authors": ["Neophytos Neophytou", "Klaus Mueller"], "_id": {"$oid": "5797a827c60b4bee2debaf16"}}, {"index": "5390b48420f70186a0efb99f", "title": "A perceptual framework for comparisons of direct volume rendered images", "abstract": "Direct volume rendering (DVR) has been widely used by physicians, scientists, and engineers in many applications. There are various DVR algorithms and the images generated by these algorithms are somewhat different. Because these direct volume rendered images will be perceived by human beings, it is important to evaluate their quality based on human perception. One of the key perceptual factors is that whether and how the visible differences between two images will be observed by users. In this paper we propose a perceptual framework, which is based on the Visible Differences Predictor (VDP), for comparing the direct volume rendered images generated with different algorithms or the same algorithm with different specifications such as shading method, gradient estimation scheme, and sampling rate. Our framework consists of a volume rendering engine and a VDP component. The experimental results on some real volume data show that the visible differences between two direct volume rendered images can be measured quantitatively with our framework. Our method can help users choose suitable DVR algorithms and specifications for their applications from a perceptual perspective and steer the visualization process.", "year": "2006", "venue": "PSIVT'06 Proceedings of the First Pacific Rim conference on Advances in Image and Video Technology", "citations": ["53909f8c20f70186a0e3f7af"], "references": ["539098b820f70186a0e0a6dc", "53909a9320f70186a0e21a7b", "539087c720f70186a0d56f63", "539087c720f70186a0d58381", "5390878720f70186a0d36057", "5390879920f70186a0d41b8b", "539087d920f70186a0d60927", "539087eb20f70186a0d6a654", "539087eb20f70186a0d6c076", "539087f320f70186a0d70f91", "5390880720f70186a0d78aee", "5390880720f70186a0d79c21", "539089ab20f70186a0d96b50", "539089bb20f70186a0d9882d", "539089bb20f70186a0d988b6", "53908ae020f70186a0dadc32", "53908af920f70186a0daff1a", "53908b4920f70186a0dbc85f"], "authors": ["Hon-Cheng Wong", "Huamin Qu", "Un-Hong Wong", "Zesheng Tang", "Klaus Mueller"], "_id": {"$oid": "5797a88fc60b4bee2df12540"}}, {"index": "53909a9320f70186a0e21a83", "title": "Visual Simulation of Heat Shimmering and Mirage", "abstract": "We provide a physically-based framework for simulating the natural phenomena related to heat interaction between objects and the surrounding air. We introduce a heat transfer model between the heat source objects and the ambient flow environment, which includes conduction, convection, and radiation. The heat distribution of the objects is represented by a novel temperature texture. We simulate the thermal flow dynamics that models the air flow interacting with the heat by a hybrid thermal lattice Boltzmann model (HTLBM). The computational approach couples a multiple-relaxation-time LBM (MRTLBM) with a finite difference discretization of a standard advection-diffusion equation for temperature. In heat shimmering and mirage, the changes in the index of refraction of the surrounding air are attributed to temperature variation. A nonlinear ray tracing method is used for rendering. Interactive performance is achieved by accelerating the computation of both the MRTLBM and the heat transfer, as well as the rendering on contemporary graphics hardware (GPU).", "year": "2007", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["53909e8b20f70186a0e2e6b8", "53909f2d20f70186a0e38751", "53909f8c20f70186a0e40c73", "5390a06e20f70186a0e4c321", "5390a1f820f70186a0e5cec1", "5390a40520f70186a0e6e714", "5390a8b220f70186a0e9cc64", "5390a9a520f70186a0ea66d0", "5390b7fe20f70186a0f27558", "5390b7fe20f70186a0f27561", "558acac9612c41e6b9d3a427"], "references": ["5390972920f70186a0dfb26a", "5390975920f70186a0dfe3ad", "5390979920f70186a0e00569", "5390985d20f70186a0e0858b", "539087d920f70186a0d625d3", "539087e120f70186a0d6586d", "539087e720f70186a0d69341", "539087f320f70186a0d70f96", "5390881720f70186a0d7fbfa", "5390882420f70186a0d89432", "539089bb20f70186a0d98d85", "53908e0020f70186a0dd4a32", "53908e0020f70186a0dd4a33", "53909ce520f70186a0e263d1"], "authors": ["Ye Zhao", "Yiping Han", "Zhe Fan", "Feng Qiu", "Yu-Chuan Kuo", "Arie E. Kaufman", "Klaus Mueller"], "_id": {"$oid": "5797a563c60b4bede9e9618d"}}, {"index": "53909a9320f70186a0e21a83", "title": "Visual Simulation of Heat Shimmering and Mirage", "abstract": "We provide a physically-based framework for simulating the natural phenomena related to heat interaction between objects and the surrounding air. We introduce a heat transfer model between the heat source objects and the ambient flow environment, which includes conduction, convection, and radiation. The heat distribution of the objects is represented by a novel temperature texture. We simulate the thermal flow dynamics that models the air flow interacting with the heat by a hybrid thermal lattice Boltzmann model (HTLBM). The computational approach couples a multiple-relaxation-time LBM (MRTLBM) with a finite difference discretization of a standard advection-diffusion equation for temperature. In heat shimmering and mirage, the changes in the index of refraction of the surrounding air are attributed to temperature variation. A nonlinear ray tracing method is used for rendering. Interactive performance is achieved by accelerating the computation of both the MRTLBM and the heat transfer, as well as the rendering on contemporary graphics hardware (GPU).", "year": "2007", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["53909e8b20f70186a0e2e6b8", "53909f2d20f70186a0e38751", "53909f8c20f70186a0e40c73", "5390a06e20f70186a0e4c321", "5390a1f820f70186a0e5cec1", "5390a40520f70186a0e6e714", "5390a8b220f70186a0e9cc64", "5390a9a520f70186a0ea66d0", "5390b7fe20f70186a0f27558", "5390b7fe20f70186a0f27561", "558acac9612c41e6b9d3a427"], "references": ["5390972920f70186a0dfb26a", "5390975920f70186a0dfe3ad", "5390979920f70186a0e00569", "5390985d20f70186a0e0858b", "539087d920f70186a0d625d3", "539087e120f70186a0d6586d", "539087e720f70186a0d69341", "539087f320f70186a0d70f96", "5390881720f70186a0d7fbfa", "5390882420f70186a0d89432", "539089bb20f70186a0d98d85", "53908e0020f70186a0dd4a32", "53908e0020f70186a0dd4a33", "53909ce520f70186a0e263d1"], "authors": ["Ye Zhao", "Yiping Han", "Zhe Fan", "Feng Qiu", "Yu-Chuan Kuo", "Arie E. Kaufman", "Klaus Mueller"], "_id": {"$oid": "5797a63dc60b4bee2dd4b9a0"}}, {"index": "5390b86b20f70186a0f2815f", "title": "Applications of optimal sampling lattices for volume acquisition via 3D computed tomography", "abstract": "There has been mounting evidence that the familiar Cartesian lattices, while convenient for signal processing and representation, are sub-optimal when it comes to signal fidelity. More suitable in this respect are optimal sampling lattices, such as the Hexagonal and Body Centered Cartesian (BCC) lattice, and recent work has employed these in the areas of volume rendering and image processing. In this paper we explore various applications of these lattices within the context of 3D Computed Tomographic Reconstruction, both in terms of the (2D) detector and the (3D) reconstructed object, and a theoretical analysis is provided. We combine this analysis with a practical application, that is, the use of these lattices within a real-time GPU-accelerated 3D reconstruction platform, in which performance is also of an immediate concern.", "year": "2007", "venue": "VG'07 Proceedings of the Sixth Eurographics / Ieee VGTC conference on Volume Graphics", "citations": ["5390b71120f70186a0f1f5c3", "5390b95520f70186a0f2f793"], "references": ["5390979920f70186a0e00526", "53909eef20f70186a0e36a76", "5390b64020f70186a0f19abc", "5390b7ff20f70186a0f278d7", "5390878720f70186a0d34c36", "5390893e20f70186a0d92ed7", "539089ab20f70186a0d96a90", "53908b4920f70186a0dbb888", "5390958a20f70186a0defa93"], "authors": ["Fang Xu", "Klaus Mueller"], "_id": {"$oid": "5797a6d7c60b4bee2ddc3fbf"}}, {"index": "53909f8c20f70186a0e3f7af", "title": "Conjoint Analysis to Measure the Perceived Quality in Volume Rendering", "abstract": "Visualization algorithms can have a large number of parameters, making the space of possible rendering results rather high-dimensional. Only a systematic analysis of the perceived quality can truly reveal the optimal setting for each such parameter. However, an exhaustive search in which all possible parameter permutations are presented to each user within a study group would be infeasible to conduct. Additional complications may result from possible parameter co-dependencies. Here, we will introduce an efficient user study design and analysis strategy that is geared to cope with this problem. The user feedback is fast and easy to obtain and does not require exhaustive parameter testing. To enable such a framework we have modified a preference measuring methodology, conjoint analysis, that originated in psychology and is now also widely used in market research. We demonstrate our framework by a study that measures the perceived quality in volume rendering within the context of large parameter spaces.", "year": "2007", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["5390a25820f70186a0e5f4f2", "5390a72220f70186a0e8aac0", "5390a96f20f70186a0ea45b4", "5390b13020f70186a0edd3ac", "5390b95520f70186a0f2f749"], "references": ["539098b820f70186a0e0a6f7", "5390990f20f70186a0e10041", "539099a220f70186a0e17086", "53909a0220f70186a0e1f08b", "53909a9320f70186a0e21aa0", "53909a9320f70186a0e21ac0", "53909a9320f70186a0e21aa9", "5390b48420f70186a0efb99f"], "authors": ["Joachim Giesen", "Klaus Mueller", "Eva Schuberth", "Lujin Wang", "Peter Zolliker"], "_id": {"$oid": "5797a6eac60b4bee2ddd1460"}}, {"index": "5390a45620f70186a0e733d7", "title": "ClusterSculptor: A Visual Analytics Tool for High-Dimensional Data", "abstract": "Cluster analysis (CA) is a powerful strategy for the exploration of high-dimensional data in the absence of a-priori hypotheses or data classification models, and the results of CA can then be used to form such models. But even though formal models and classification rules may not exist in these data exploration scenarios, domain scientists and experts generally have a vast amount of non-compiled knowledge and intuition that they can bring to bear in this effort. In CA, there are various popular mechanisms to generate the clusters, however, the results from their non-supervised deployment rarely fully agree with this expert knowledge and intuition. To this end, our paper describes a comprehensive and intuitive framework to aid scientists in the derivation of classification hierarchies in CA, using k-means as the overall clustering engine, but allowing them to tune its parameters interactively based on a non-distorted compact visual presentation of the inherent characteristics of the data in high-dimensional space. These include cluster geometry, composition, spatial relations to neighbors, and others. In essence, we provide all the tools necessary for a high-dimensional activity we call cluster sculpting, and the evolving hierarchy can then be viewed in a space-efficient radial dendrogram. We demonstrate our system in the context of the mining and classification of a large collection of millions of data items of aerosol mass spectra, but our framework readily applies to any high-dimensional CA scenario.", "year": "2007", "venue": "VAST '07 Proceedings of the 2007 IEEE Symposium on Visual Analytics Science and Technology", "citations": ["5390a0b720f70186a0e4f6a0", "5390a2be20f70186a0e64b75", "5390a5b020f70186a0e7de58", "5390a72220f70186a0e8aac0", "5390a88c20f70186a0e99f55", "5390b95520f70186a0f2f752", "55323d1d45cec66b6f9dd949"], "references": [], "authors": ["Eun Ju Nam", "Yiping Han", "Klaus Mueller", "Alla Zelenyuk", "Dan Imre"], "_id": {"$oid": "5797a73bc60b4bee2de0ba78"}}, {"index": "5390b64020f70186a0f1a701", "title": "Coding Algorithms for 3DTV\u2014A Survey", "abstract": "Research efforts on 3DTV technology have been strengthened worldwide recently, covering the whole media processing chain from capture to display. Different 3DTV systems rely on different 3D scene representations that integrate various types of data. Efficient coding of these data is crucial for the success of 3DTV. Compression of pixel-type data including stereo video, multiview video, and associated depth or disparity maps extends available principles of classical video coding. Powerful algorithms and open international standards for multiview video coding and coding of video plus depth data are available and under development, which will provide the basis for introduction of various 3DTV systems and services in the near future. Compression of 3D mesh models has also reached a high level of maturity. For static geometry, a variety of powerful algorithms are available to efficiently compress vertices and connectivity. Compression of dynamic 3D geometry is currently a more active field of research. Temporal prediction is an important mechanism to remove redundancy from animated 3D mesh sequences. Error resilience is important for transmission of data over error prone channels, and multiple description coding (MDC) is a suitable way to protect data. MDC of still images and 2D video has already been widely studied, whereas multiview video and 3D meshes have been addressed only recently. Intellectual property protection of 3D data by watermarking is a pioneering research area as well. The 3D watermarking methods in the literature are classified into three groups, considering the dimensions of the main components of scene representations and the resulting components after applying the algorithm. In general, 3DTV coding technology is maturating. Systems and services may enter the market in the near future. However, the research area is relatively young compared to coding of other types of media. Therefore, there is still a lot of room for improvement and new development o- f algorithms.", "year": "2007", "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "citations": ["5390a25820f70186a0e5e7bb", "5390a25820f70186a0e5f7ab", "5390a2e920f70186a0e677b7", "5390a40520f70186a0e70921", "5390a55520f70186a0e793bf", "5390a5b020f70186a0e7dc87", "5390a7f520f70186a0e92eaa", "5390a7f520f70186a0e92ec6", "5390a7f520f70186a0e92ee1", "5390a7f620f70186a0e94795", "5390a7f620f70186a0e94c58", "5390a7f620f70186a0e94c57", "5390aa7620f70186a0eaab56", "5390aaf920f70186a0ead6ab", "5390aaf920f70186a0eae4c7", "5390ac1820f70186a0eb428b", "5390aca820f70186a0eb898d", "5390aca820f70186a0eb8ae9", "5390adfd20f70186a0ec5481", "5390b00c20f70186a0ed5274", "5390b13020f70186a0ede0b5", "5390b29820f70186a0ee92a7", "5390b2fc20f70186a0eedcd4", "5390b44620f70186a0ef7f7c", "5390b44620f70186a0ef8f53", "5390b48420f70186a0efacf4", "5390b48420f70186a0eface9", "5390b78a20f70186a0f238a9", "5390b78a20f70186a0f24635", "5390b7fe20f70186a0f26564", "5390b7fe20f70186a0f26b2f", "5390b7fe20f70186a0f270d4", "5390b95520f70186a0f2fa67", "5390bae620f70186a0f3bee8", "5390bb1d20f70186a0f3c9f0", "558b3407612c41e6b9d467f2", "558b0c93612c41e6b9d41745"], "references": [], "authors": ["A. Smolic", "K. Mueller", "N. Stefanoski", "J. Ostermann", "A. Gotchev", "G. B. Akar", "G. Triantafyllidis", "A. Koz"], "_id": {"$oid": "5797a837c60b4bee2dec7f4e"}}, {"index": "5390b7ff20f70186a0f27713", "title": "Subdivision volume splatting", "abstract": "Volumetric Subdivision (VS) is a powerful paradigm that enables volumetric sculpting and realistic volume deformations that give rise to the concept of \"virtual clay\". In VS, volumes are commonly represented as a space-filling set of deformed polyhedra, which can be further decomposed into a mesh of tetrahedra for rendering. Images can then be generated via tetrahedral projection or raycasting. A current shortcoming in VS-based operations is the need for a very high level of subdivision to represent fine detail in the mesh and to obtain a high-fidelity visualization. However, we have discovered that the subdivision process itself can be closely simulated with radial basis functions (RBFs), making it possible to replace the finer subdivision levels by a coarser aggregation of RBF kernels. This reduction to a simplified assembly of RBFs subsequently enables interactive rendering of volumetric subdivision shapes within a GPU-based volume splatting framework.", "year": "2007", "venue": "EUROVIS'07 Proceedings of the 9th Joint Eurographics / IEEE VGTC conference on Visualization", "citations": [], "references": ["5390975920f70186a0dfc801", "5390979920f70186a0e011a4", "5390981d20f70186a0e043c1", "539098b820f70186a0e0a6ee", "539098b820f70186a0e0b3d2", "539098dc20f70186a0e0cc71", "53909a9320f70186a0e21a8e", "53909ed120f70186a0e30e4f", "5390b5df20f70186a0f0b630", "5390879920f70186a0d41b8b", "5390879920f70186a0d42039", "539087eb20f70186a0d6a669", "539087f320f70186a0d70f95", "5390881220f70186a0d7e16b", "5390881720f70186a0d8040c", "5390881820f70186a0d8164e", "5390882420f70186a0d89422", "5390882d20f70186a0d8de04", "539089bb20f70186a0d9881d", "53908bcc20f70186a0dc557b", "5390958a20f70186a0defce4", "5390b7ff20f70186a0f2772a", "5390b7ff20f70186a0f278be"], "authors": ["K. T. McDonnell", "Neophytos Neophytou", "Klaus Mueller", "Hong Qin"], "_id": {"$oid": "5797a83bc60b4bee2decb54f"}}, {"index": "53909f8c20f70186a0e3f76b", "title": "Lattice-Based Volumetric Global Illumination", "abstract": "We describe a novel volumetric global illumination framework based on the Face-Centered Cubic (FCC) lattice. An FCC lattice has important advantages over a Cartesian lattice. It has higher packing density in the frequency domain, which translates to better sampling efficiency. Furthermore, it has the maximal possible kissing number (equivalent to the number of nearest neighbors of each site), which provides optimal 3D angular discretization among all lattices. We employ a new two-pass (illumination and rendering) global illumination scheme on an FCC lattice. This scheme exploits the angular discretization to greatly simplify the computation in multiple scattering and to minimize illumination information storage. The GPU has been utilized to further accelerate the rendering stage. We demonstrate our new framework with participating media and volume rendering with multiple scattering, where both are significantly faster than traditional techniques with comparable quality.", "year": "2007", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["5390a7f520f70186a0e9428e", "5390b7fe20f70186a0f27549", "5390b86b20f70186a0f28072", "5390b86b20f70186a0f2811b", "5390ba0a20f70186a0f343ee"], "references": ["5390979920f70186a0e00526", "5390980720f70186a0e041e5", "539098b820f70186a0e0a6dc", "5390878720f70186a0d34661", "5390878720f70186a0d34c36", "539087c720f70186a0d58417", "539087e720f70186a0d6932d", "539087eb20f70186a0d6a655", "539088b820f70186a0d905eb", "5390893e20f70186a0d92ed7", "539089ab20f70186a0d96a90", "539089bb20f70186a0d987f7", "53908b4920f70186a0dbc861", "53908b9320f70186a0dc153f", "53908bad20f70186a0dc3150", "5390962020f70186a0df430c", "5390b5c620f70186a0f08b32", "5390b7fe20f70186a0f2752f", "5390b7fe20f70186a0f27531"], "authors": ["Feng Qiu", "Fang Xu", "Zhe Fan", "Neophytou Neophytos", "Arie Kaufman", "Klaus Mueller"], "_id": {"$oid": "5797a8f0c60b4bee2df62270"}}, {"index": "5390b95520f70186a0f2f736", "title": "Illustrative parallel coordinates", "abstract": "Illustrative parallel coordinates (IPC) is a suite of artistic rendering techniques for augmenting and improving parallel coordinate (PC) visualizations. IPC techniques can be used to convey a large amount of information about a multidimensional dataset in a small area of the screen through the following approaches: (a) edgebundling through splines; (b) visualization of \"branched\" clusters to reveal the distribution of the data; (c) opacitybased hints to show cluster density; (d) opacity and shading effects to illustrate local line density on the parallel axes; and (e) silhouettes, shadows and halos to help the eye distinguish between overlapping clusters. Thus, the primary goal of this work is to convey as much information as possible in a manner that is aesthetically pleasing and easy to understand for non-experts.", "year": "2008", "venue": "EuroVis'08 Proceedings of the 10th Joint Eurographics / IEEE - VGTC conference on Visualization", "citations": ["5390a2be20f70186a0e64bd4", "5390ac1820f70186a0eb3fff", "5390aca920f70186a0eb9330", "5390b24320f70186a0ee64fb", "5390b5ed20f70186a0f0c337", "5390b86b20f70186a0f2a405", "5390b95520f70186a0f2f73f", "5390b95520f70186a0f2f755", "5390b95520f70186a0f2f77a", "5390b95520f70186a0f2f799", "5390b95520f70186a0f2f7b5", "5390b95520f70186a0f2f744", "558b2da2612c41e6b9d45c94", "558b16b1612c41e6b9d42c49"], "references": ["5390979920f70186a0e010c7", "5390990f20f70186a0e10037", "53909a9320f70186a0e21ad5", "53909a9320f70186a0e21a84", "53909a9320f70186a0e21aa5", "539087aa20f70186a0d4b5e9", "5390b7ff20f70186a0f27706", "539087f820f70186a0d72a2c", "539089bb20f70186a0d9888c", "539089bb20f70186a0d988b1", "539089bb20f70186a0d98fc5", "53908bad20f70186a0dc2d3a", "53908cde20f70186a0dcd8d8", "5390956e20f70186a0ded95e", "5390958a20f70186a0def693"], "authors": ["K. T. McDonnell", "K. Mueller"], "_id": {"$oid": "5797a688c60b4bee2dd88e60"}}, {"index": "5390a2be20f70186a0e64b57", "title": "Enclosed Five-Wall Immersive Cabin", "abstract": "We present a novel custom-built 3D immersive environment, called the Immersive Cabin (IC). The IC is fully enclosed with an automatic door on the rear screen, and thus very different from existing CAVE environments. Our IC, the construction of the projection screens and stereo projectors as well as the calibration procedure are explained in details. The projectors are driven by our Visual Computing cluster for computation and rendering. Three applications that have been developed on the IC are described, 3D virtual colonoscopy, dispersion simulation for urban security, and 3D imagery and artistic creations.", "year": "2008", "venue": "ISVC '08 Proceedings of the 4th International Symposium on Advances in Visual Computing", "citations": [], "references": ["5390972920f70186a0dfb54e", "5390980720f70186a0e01f9c", "5390980720f70186a0e03742", "53909a0320f70186a0e20b7e", "53908bde20f70186a0dc7384"], "authors": ["Feng Qiu", "Bin Zhang", "Kaloian Petkov", "Lance Chong", "Arie Kaufman", "Klaus Mueller", "Xianfeng David Gu"], "_id": {"$oid": "5797a76bc60b4bee2de2f7e2"}}, {"index": "5390b86b20f70186a0f28112", "title": "Harmonic colormaps for volume visualization", "abstract": "Color design forms a crucial part in visual aesthetics, and it has been shown that a visually aesthetic visualization will be looked at more carefully. An important role plays here the choice of a colormap that is composed of harmonic colors. This paper presents an interface that allows users to choose harmonic colors in volume visualization applications. In addition, it describes mechanisms by which non-harmonic colormaps can be converted to harmonic ones, but keeping lightness constant to preserve the original contrast relationships. Finally, we also show how harmonic colors can be used for the highlighting of important volume features.", "year": "2008", "venue": "SPBG'08 Proceedings of the Fifth Eurographics / IEEE VGTC conference on Point-Based Graphics", "citations": ["5390ac5720f70186a0eb66a6", "5390b64020f70186a0f1aabd"], "references": ["539099a220f70186a0e17e90", "53909a9320f70186a0e21aa9", "5390a28020f70186a0e62b92", "539087be20f70186a0d51693", "5390b5df20f70186a0f0ad1d", "5390b7fe20f70186a0f26ea0", "539087dd20f70186a0d62a30", "5390882420f70186a0d8902b", "539089ab20f70186a0d96a9c", "539089ab20f70186a0d96b4e", "53908bcc20f70186a0dc6cd6", "53908cde20f70186a0dce969", "5390958a20f70186a0def780", "539096cb20f70186a0df6aa0", "5390b95520f70186a0f2f712"], "authors": ["Lujin Wang", "Klaus Mueller"], "_id": {"$oid": "5797a7b2c60b4bee2de66540"}}, {"index": "5390a28020f70186a0e62b92", "title": "Color Design for Illustrative Visualization", "abstract": "Professional designers and artists are quite cognizant of the rules that guide the design of effective color palettes, from both aesthetic and attention-guiding points of view. In the field of visualization, however, the use of systematic rules embracing these aspects has received less attention. The situation is further complicated by the fact that visualization often uses semi-transparencies to reveal occluded objects, in which case the resulting color mixing effects add additional constraints to the choice of the color palette. Color design forms a crucial part in visual aesthetics. Thus, the consideration of these issues can be of great value in the emerging field of illustrative visualization. We describe a knowledge-based system that captures established color design rules into a comprehensive interactive framework, aimed to aid users in the selection of colors for scene objects and incorporating individual preferences, importance functions, and overall scene composition. Our framework also offers new knowledge and solutions for the mixing, ordering and choice of colors in the rendering of semi-transparent layers and surfaces. All design rules are evaluated via user studies, for which we extend the method of conjoint analysis to task-based testing scenarios. Our framework\u2019s use of principles rooted in color design with application for the illustration of features in pre-classified data distinguishes it from existing systems which target the exploration of continuous-range density data via perceptual color maps.", "year": "2008", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["5390ac1820f70186a0eb3fff", "5390aefc20f70186a0ece256", "5390b19020f70186a0edff88", "5390b52620f70186a0f036ce", "5390b64020f70186a0f1aabd", "5390b86b20f70186a0f28112", "5390b95520f70186a0f2f754", "5390bed320f70186a0f4d8a0", "558b8706612c6b62e5e8abf5", "5390bfa220f70186a0f54c18", "558b1b48612c41e6b9d43757", "55913dfc0cf232eb904fb6b8"], "references": [], "authors": ["Lujin Wang", "Joachim Giesen", "Kevin T. McDonnell", "Peter Zolliker", "Klaus Mueller"], "_id": {"$oid": "5797a7ccc60b4bee2de6dcf4"}}, {"index": "5390a06e20f70186a0e4bb8a", "title": "Color-Space CAD: Direct Gamut Editing in 3D", "abstract": "Color-Space CAD is an interactive image-processing framework that lets users manipulate colors directly in 3D perceptual color space. Unlike traditional 2D color-manipulation tools, which often require multiple iterations, Color-Space CAD allows direct 3D navigation of the solution space. The framework uses graphics hardware to accelerate the computation-intensive mapping operations.", "year": "2008", "venue": "IEEE Computer Graphics and Applications", "citations": ["5390b19020f70186a0edff88"], "references": [], "authors": ["Neophytos Neophytou", "Klaus Mueller"], "_id": {"$oid": "5797a7d3c60b4bee2de74729"}}, {"index": "5390a2be20f70186a0e64251", "title": "Physical-Space Refraction-Corrected Transmission Ultrasound Computed Tomography Made Computationally Practical", "abstract": "Transmission Ultrasound Computed Tomography (CT) is strongly affected by the acoustic refraction properties of the imaged tissue, and proper modeling and correction of these effects is crucial to achieving high-quality image reconstructions. A method that can account for these refractive effects solves the governing Eikonal equation within an iterative reconstruction framework, using a wave-front tracking approach. Excellent results can be obtained, but at considerable computational expense. Here, we report on the acceleration of three Eikonal solvers (Fast Marching Method (FMM), Fast Sweeping Method (FSM), Fast Iterative Method (FIM)) on three computational platforms (commodity graphics hardware (GPUs), multi-core and cluster CPUs), within this refractive Transmission Ultrasound CT framework. Our efforts provide insight into the capabilities of the various architectures for acoustic wave-front tracking, and they also yield a framework that meets the interactive demands of clinical practice, without a loss in reconstruction quality.", "year": "2008", "venue": "MICCAI '08 Proceedings of the 11th International Conference on Medical Image Computing and Computer-Assisted Intervention, Part II", "citations": ["558b148f612c41e6b9d426f1"], "references": ["5390995d20f70186a0e15e6d", "53909f8c20f70186a0e3f75b", "5390882d20f70186a0d8def4", "5390893e20f70186a0d93a21", "53908b4920f70186a0dbb174"], "authors": ["Shengying Li", "Klaus Mueller", "Marcel Jackowski", "Donald Dione", "Lawrence Staib"], "_id": {"$oid": "5797a7d4c60b4bee2de74d57"}}, {"index": "5390adfd20f70186a0ec5f89", "title": "Analyzing root causes of latency distributions", "abstract": "OSprof is a versatile, portable, and efficient profiling methodology based on the analysis of latency distributions. Although OSprof offers several unique benefits and has been used to uncover several interesting performance problems, the latency distributions that it provides must be analyzed manually. These latency distributions are presented as histograms and contain distinct groups of data, called peaks, that characterize the overall behavior of the running code. Our thesis is that by automating the analysis process, we make it easier to take advantage of OSprof\u2019s unique features. We have developed the Dynamic Analysis of Root Causes system (DARC), which finds root cause paths in a running program\u2019s call-graph using runtime latency analysis. A root cause path is a call-path that starts at a given function and includes the largest latency contributors to a given peak. These paths are the main causes for the high-level behavior that is represented as a peak in an OSprof histogram. DARC uses dynamic binary instrumentation to analyze running code. DARC performs PID and call-path filtering to reduce overheads and perturbations, and can handle recursive and indirect calls. DARC can analyze preemptive behavior and asynchronous call-paths, and can also resume its analysis from a previous state, which is useful when analyzing short-running programs or specific phases of a program\u2019s execution. In this dissertation we present the design and implementation of DARC. Our implementation is able to find user-space and kernel-space root cause paths, as well as paths that originate in user-space and terminate in kernel-space. We also investigate the possibility of using OSprof and DARC in virtual machine environments. We show DARC\u2019s usefulness by analyzing behaviors that were observed in several interesting scenarios. We compared the analysis of these behaviors when using DARC to the manual analysis required by the original OSprof methodology, and found that DARC provides more concrete evidence about root causes while requiring less time, expertise, and intuition. In our performance evaluation, we show that DARC has negligible elapsed time overheads for normal use cases.", "year": "2008", "venue": "Analyzing root causes of latency distributions", "citations": [], "references": [], "authors": ["Erez Zadok", "Klaus Mueller", "Avishay Traeger"], "_id": {"$oid": "5797a7dac60b4bee2de7a8e5"}}, {"index": "5390a7f620f70186a0e950e9", "title": "Accelerating regularized iterative CT reconstruction on commodity graphics hardware (GPU)", "abstract": "Iterative reconstruction algorithms augmented with regularization can produce high-quality reconstructions from few views and even in the presence of significant noise. In this paper we focus on the particularities associated with the GPU acceleration of these. First, we introduce the idea of using exhaustive benchmark tests to determine the optimal settings of various parameters in iterative algorithm, here OS-SIRT, which proofs decisive for obtaining optimal GPU performance. Then we introduce bilateral filtering as a viable and cost-effective means for regularization, and we show that GPU-acceleration reduces its overhead to very moderate levels.", "year": "2009", "venue": "ISBI'09 Proceedings of the Sixth IEEE international conference on Symposium on Biomedical Imaging: From Nano to Macro", "citations": ["5390ad0620f70186a0eba515"], "references": ["5390956e20f70186a0ded7b2"], "authors": ["Wei Xu", "Klaus Mueller"], "_id": {"$oid": "5797a6acc60b4bee2dda643d"}}, {"index": "5390a5b020f70186a0e7d631", "title": "Efficient LBM Visual Simulation on Face-Centered Cubic Lattices", "abstract": "The Lattice Boltzmann method (LBM) for visual simulation of fluid flow generally employs cubic Cartesian (CC) lattices such as the D3Q13 and D3Q19 lattices for the particle transport. However, the CC lattices lead to suboptimal representation of the simulation space. We introduce the face-centered cubic (FCC) lattice, fD3Q13, for LBM simulations. Compared to the CC lattices, the fD3Q13 lattice creates a more isotropic sampling of the simulation domain and its single lattice speed (i.e., link length) simplifies the computations and data storage. Furthermore, the fD3Q13 lattice can be decomposed into two independent interleaved lattices, one of which can be discarded, which doubles the simulation speed. The resulting LBM simulation can be efficiently mapped to the GPU, further increasing the computational performance. We show the numerical advantages of the FCC lattice on channeled flow in 2D and the flow-past-a-sphere benchmark in 3D. In both cases, the comparison is against the corresponding CC lattices using the analytical solutions for the systems as well as velocity field visualizations. We also demonstrate the performance advantages of the fD3Q13 lattice for interactive simulation and rendering of hot smoke in an urban environment using thermal LBM.", "year": "2009", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["5390b19020f70186a0edf8ea", "5390ba0a20f70186a0f343ee", "5390bb7b20f70186a0f40f50"], "references": [], "authors": ["Kaloian Petkov", "Feng Qiu", "Zhe Fan", "Arie E. Kaufman", "Klaus Mueller"], "_id": {"$oid": "5797a820c60b4bee2deb51f2"}}, {"index": "5390a72220f70186a0e8aac0", "title": "Knowledge Assisted Visualization: A high-dimensional feature clustering approach to support knowledge-assisted visualization", "abstract": "The ever-growing arsenal of methods and parameters available for data visualization can be daunting to the casual user and even to domain experts. Furthermore, comprehensive expertise is often not available in a centralized venue, but distributed over sub-communities. As a means to overcome this inherent problem, efforts have begun to store visualization expertise directly with the visualization method and possibly the dataset, to then be utilized for user guidance in the data visualization, suggesting to the user both the visualization method and its best parameters for the data and task at hand. While this is certainly an immensely useful and promising development, one requirement remains - the matching of a newly acquired dataset with the appropriate segment of the library storing the expert knowledge. This requires one to detect and recognize the dataset's category at some level of granularity and then use this information as a library index. We describe a possible framework for accomplishing the first stage of this process, namely the data categorization, using data classification via a rich set of feature vectors sufficiently sensitive to detect critical variations. We demonstrate the utility of our framework by ways of a set of medical and computational datasets and visualize the resulting categorization as a layout in 2D.", "year": "2009", "venue": "Computers and Graphics", "citations": ["5390b86b20f70186a0f2a40a", "5390bded20f70186a0f492a5", "558b8f12612c6b62e5e8b85f"], "references": ["5390981d20f70186a0e043c0", "5390990f20f70186a0e10e30", "53909a0220f70186a0e1f08c", "53909a9320f70186a0e21ab1", "53909f8c20f70186a0e3f7af", "539087aa20f70186a0d4aa2a", "5390a28020f70186a0e62bc0", "5390a28020f70186a0e62bc2", "5390a2e920f70186a0e670f0", "5390a45620f70186a0e733d7", "5390a5b020f70186a0e7d2f1", "5390877920f70186a0d2cf38", "539087c720f70186a0d58381", "539087e720f70186a0d69653", "539087eb20f70186a0d6c063", "539089ab20f70186a0d96aa2", "539089ab20f70186a0d96b40", "539089bb20f70186a0d98819", "539089bb20f70186a0d988ce", "53908a5720f70186a0da08de", "53908bfb20f70186a0dcac95", "5390958920f70186a0deeffc", "5390958a20f70186a0def693", "5390958a20f70186a0df03e0", "5390972820f70186a0df9a93", "5390b7ff20f70186a0f27712"], "authors": ["Julia EunJu Nam", "Mauricio Maurer", "Klaus Mueller"], "_id": {"$oid": "5797a854c60b4bee2dedf3fb"}}, {"index": "5390ada620f70186a0ec2491", "title": "VDVR: Verifiable Volume Visualization of Projection-Based Data", "abstract": "Practical volume visualization pipelines are never without compromises and errors. A delicate and often-studied component is the interpolation of off-grid samples, where aliasing can lead to misleading artifacts and blurring, potentially hiding fine details of critical importance. The verifiable visualization framework we describe aims to account for these errors directly in the volume generation stage, and we specifically target volumetric data obtained via computed tomography (CT) reconstruction. In this case the raw data are the X-ray projections obtained from the scanner and the volume data generation process is the CT algorithm. Our framework informs the CT reconstruction process of the specific filter intended for interpolation in the subsequent visualization process, and this in turn ensures an accurate interpolation there at a set tolerance. Here, we focus on fast trilinear interpolation in conjunction with an octree-type mixed resolution volume representation without T-junctions. Efficient rendering is achieved by a space-efficient and locality-optimized representation, which can straightforwardly exploit fast fixed-function pipelines on GPUs.", "year": "2010", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": [], "references": [], "authors": ["Ziyi Zheng", "Wei Xu", "Klaus Mueller"], "_id": {"$oid": "5797a53cc60b4bede9e7f848"}}, {"index": "5390b36120f70186a0ef1940", "title": "Tools to enrich user experience during \"visual analysis\"", "abstract": "Visual Analytics is the integration of interactive visualization with analysis techniques to help answer questions, and find interesting \u201cpatterns\u201d in a given dataset. This approach is useful in cases where human knowledge and intuition is required. Further, with the increasing size of data, an interactive visual interface can give the user control over what she wants to see. Towards this end, we develop a Visual Analytics (VA) infrastructure, rooted on techniques in machine learning and logic-based deductive reasoning. This system assists people in making sense of large, complex data sets by facilitating the generation and validation of models representing relationships in the data. The above data is often communicated among people, and by systems as graphs and other visual forms. However, currently the degree of semantics encoded in these representations is quite limited. In order to design more expressive icons, we present a framework that uses natural language text processing and global image databases to help users identify metaphors suitable to visually encode abstract semantic concepts. While using images as forms of communication, people often like to add annotations in forms of text, arrows, etc. to make them more expressive. The process of selecting a color for the annotation can often be difficult if the background has a variation in color and texture. Our tool Magic marker helps users by suggesting appropriate colors for annotating an image. All colors in a modified CIE-Lab color-space are assigned a preference value, and users can navigate this space using an interactive interface. This interactivity also allows them to make the final choice based on personal preferences.", "year": "2010", "venue": "Tools to enrich user experience during \"visual analysis\"", "citations": [], "references": [], "authors": ["Klaus Mueller", "Supriya Garg"], "_id": {"$oid": "5797a54bc60b4bede9e8845b"}}, {"index": "5390ada620f70186a0ec2491", "title": "VDVR: Verifiable Volume Visualization of Projection-Based Data", "abstract": "Practical volume visualization pipelines are never without compromises and errors. A delicate and often-studied component is the interpolation of off-grid samples, where aliasing can lead to misleading artifacts and blurring, potentially hiding fine details of critical importance. The verifiable visualization framework we describe aims to account for these errors directly in the volume generation stage, and we specifically target volumetric data obtained via computed tomography (CT) reconstruction. In this case the raw data are the X-ray projections obtained from the scanner and the volume data generation process is the CT algorithm. Our framework informs the CT reconstruction process of the specific filter intended for interpolation in the subsequent visualization process, and this in turn ensures an accurate interpolation there at a set tolerance. Here, we focus on fast trilinear interpolation in conjunction with an octree-type mixed resolution volume representation without T-junctions. Efficient rendering is achieved by a space-efficient and locality-optimized representation, which can straightforwardly exploit fast fixed-function pipelines on GPUs.", "year": "2010", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": [], "references": [], "authors": ["Ziyi Zheng", "Wei Xu", "Klaus Mueller"], "_id": {"$oid": "5797a622c60b4bee2dd3505b"}}, {"index": "5390b36120f70186a0ef1940", "title": "Tools to enrich user experience during \"visual analysis\"", "abstract": "Visual Analytics is the integration of interactive visualization with analysis techniques to help answer questions, and find interesting \u201cpatterns\u201d in a given dataset. This approach is useful in cases where human knowledge and intuition is required. Further, with the increasing size of data, an interactive visual interface can give the user control over what she wants to see. Towards this end, we develop a Visual Analytics (VA) infrastructure, rooted on techniques in machine learning and logic-based deductive reasoning. This system assists people in making sense of large, complex data sets by facilitating the generation and validation of models representing relationships in the data. The above data is often communicated among people, and by systems as graphs and other visual forms. However, currently the degree of semantics encoded in these representations is quite limited. In order to design more expressive icons, we present a framework that uses natural language text processing and global image databases to help users identify metaphors suitable to visually encode abstract semantic concepts. While using images as forms of communication, people often like to add annotations in forms of text, arrows, etc. to make them more expressive. The process of selecting a color for the annotation can often be difficult if the background has a variation in color and texture. Our tool Magic marker helps users by suggesting appropriate colors for annotating an image. All colors in a modified CIE-Lab color-space are assigned a preference value, and users can navigate this space using an interactive interface. This interactivity also allows them to make the final choice based on personal preferences.", "year": "2010", "venue": "Tools to enrich user experience during \"visual analysis\"", "citations": [], "references": [], "authors": ["Klaus Mueller", "Supriya Garg"], "_id": {"$oid": "5797a62dc60b4bee2dd3dc6e"}}, {"index": "5390aa7620f70186a0eab409", "title": "On the efficiency of iterative ordered subset reconstruction algorithms for acceleration on GPUs", "abstract": "Expectation Maximization (EM) and the Simultaneous Iterative Reconstruction Technique (SIRT) are two iterative computed tomography reconstruction algorithms often used when the data contain a high amount of statistical noise, have been acquired from a limited angular range, or have a limited number of views. A popular mechanism to increase the rate of convergence of these types of algorithms has been to perform the correctional updates within subsets of the projection data. This has given rise to the method of Ordered Subsets EM (OS-EM) and the Simultaneous Algebraic Reconstruction Technique (SART). Commodity graphics hardware (GPUs) has shown great promise to combat the high computational demands incurred by iterative reconstruction algorithms. However, we find that the special architecture and programming model of GPUs add extra constraints on the real-time performance of ordered subsets algorithms, counteracting the speedup benefits of smaller subsets observed on CPUs. This gives rise to new relationships governing the optimal number of subsets as well as relaxation factor settings for obtaining the smallest wall-clock time for reconstruction-a factor that is likely application-dependent. In this paper we study the generalization of SIRT into Ordered Subsets SIRT and show that this allows one to optimize the computational performance of GPU-accelerated iterative algebraic reconstruction methods.", "year": "2010", "venue": "Computer Methods and Programs in Biomedicine", "citations": ["5390bd1520f70186a0f4363d", "5390bded20f70186a0f48659"], "references": ["53908cde20f70186a0dce5e6"], "authors": ["Fang Xu", "Wei Xu", "Mel Jones", "Bettina Keszthelyi", "John Sedat", "David Agard", "Klaus Mueller"], "_id": {"$oid": "5797a6ddc60b4bee2ddc832b"}}, {"index": "5390b20120f70186a0ee5086", "title": "iView: A Feature Clustering Framework for Suggesting Informative Views in Volume Visualization", "abstract": "The unguided visual exploration of volumetric data can be both a challenging and a time-consuming undertaking. Identifying a set of favorable vantage points at which to start exploratory expeditions can greatly reduce this effort and can also ensure that no important structures are being missed. Recent research efforts have focused on entropy-based viewpoint selection criteria that depend on scalar values describing the structures of interest. In contrast, we propose a viewpoint suggestion pipeline that is based on feature-clustering in high-dimensional space. We use gradient/normal variation as a metric to identify interesting local events and then cluster these via k-means to detect important salient composite features. Next, we compute the maximum possible exposure of these composite feature for different viewpoints and calculate a 2D entropy map parameterized in longitude and latitude to point out promising view orientations. Superimposed onto an interactive track-ball interface, users can then directly use this entropy map to quickly navigate to potentially interesting viewpoints where visibility-based transfer functions can be employed to generate volume renderings that minimize occlusions. To give full exploration freedom to the user, the entropy map is updated on the fly whenever a view has been selected, pointing to new and promising but so far unseen view directions. Alternatively, our system can also use a set-cover optimization algorithm to provide a minimal set of views needed to observe all features. The views so generated could then be saved into a list for further inspection or into a gallery for a summary presentation.", "year": "2011", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["5390bfa220f70186a0f54c19"], "references": [], "authors": ["Ziyi Zheng", "Nafees Ahmed", "Klaus Mueller"], "_id": {"$oid": "5797a57bc60b4bede9ea4dd5"}}, {"index": "5390b20120f70186a0ee5086", "title": "iView: A Feature Clustering Framework for Suggesting Informative Views in Volume Visualization", "abstract": "The unguided visual exploration of volumetric data can be both a challenging and a time-consuming undertaking. Identifying a set of favorable vantage points at which to start exploratory expeditions can greatly reduce this effort and can also ensure that no important structures are being missed. Recent research efforts have focused on entropy-based viewpoint selection criteria that depend on scalar values describing the structures of interest. In contrast, we propose a viewpoint suggestion pipeline that is based on feature-clustering in high-dimensional space. We use gradient/normal variation as a metric to identify interesting local events and then cluster these via k-means to detect important salient composite features. Next, we compute the maximum possible exposure of these composite feature for different viewpoints and calculate a 2D entropy map parameterized in longitude and latitude to point out promising view orientations. Superimposed onto an interactive track-ball interface, users can then directly use this entropy map to quickly navigate to potentially interesting viewpoints where visibility-based transfer functions can be employed to generate volume renderings that minimize occlusions. To give full exploration freedom to the user, the entropy map is updated on the fly whenever a view has been selected, pointing to new and promising but so far unseen view directions. Alternatively, our system can also use a set-cover optimization algorithm to provide a minimal set of views needed to observe all features. The views so generated could then be saved into a list for further inspection or into a gallery for a summary presentation.", "year": "2011", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["5390bfa220f70186a0f54c19"], "references": [], "authors": ["Ziyi Zheng", "Nafees Ahmed", "Klaus Mueller"], "_id": {"$oid": "5797a64ec60b4bee2dd5a5e8"}}, {"index": "5390b20120f70186a0ee5053", "title": "Message from the Paper Chairs and Guest Editors", "abstract": "", "year": "2011", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["5390b86b20f70186a0f29689"], "references": [], "authors": ["Frank van Ham", "Raghu Machiraju", "Klaus Mueller", "Gerik Scheuermann", "Chris Weaver"], "_id": {"$oid": "5797a6dec60b4bee2ddc90d1"}}, {"index": "5390afc920f70186a0ed203f", "title": "Can Computers Master the Art of Communication?: A Focus on Visual Analytics", "abstract": "Visual analytics is a powerful paradigm for gaining insight from large, complex data. It seeks to engage the analyst more deeply in data exploration, allowing for iterative sense-making using visual interaction for fast, intuitive human-computer communication. Although researchers have made much progress in this field, the computer still plays a relatively passive role, reduced mostly to number crunching and record keeping. How can we make the computer a more active participant in the reasoning process? Can a computer be more of a mediator and collaborating partner in this insight-gathering task? A first step toward this goal is to determine how to make a computer a better communicator of the \"insight\" it has acquired, and so appeal to the human analyst as a source for creative input. This insight is typically available as some form of formatted knowledge\u2014a computational model. This article draws parallels from established rules of human interpersonal communication. It suggests equivalents by which a computer might use these communication channels, elements, and instruments, employing visual interaction as the bilateral medium.", "year": "2011", "venue": "IEEE Computer Graphics and Applications", "citations": [], "references": [], "authors": ["Klaus Mueller", "Supriya Garg", "Julia EunJu Nam", "Tamara Berg", "Kevin T. McDonnell"], "_id": {"$oid": "5797a78ec60b4bee2de4a87c"}}, {"index": "5390b13020f70186a0edd3ac", "title": "Iconizer: a framework to identify and create effective representations for visual information encoding", "abstract": "The majority of visual communication today occurs by ways of spatial groupings, plots, graphs, data renderings, photographs and video frames. However, the degree of semantics encoded in these visual representations is still quite limited. The use of icons as a form of information encoding has been explored to a much lesser extent. In this paper we describe a framework that uses a dual domain approach involving natural language text processing and global image databases to help users identify icons suitable to visually encode abstract semantic concepts.", "year": "2011", "venue": "SG'11 Proceedings of the 11th international conference on Smart graphics", "citations": [], "references": ["5390979920f70186a0dfed35", "5390995c20f70186a0e144e1", "539099a220f70186a0e17eaa", "53909f2d20f70186a0e3829a", "53909f2d20f70186a0e38719", "53909f8c20f70186a0e3f7af", "5390a01420f70186a0e46829", "5390a28020f70186a0e62f1d", "539087eb20f70186a0d6b8db", "5390881720f70186a0d7fc32", "5390882420f70186a0d891da", "539089ab20f70186a0d95f7a", "539089d220f70186a0d9ad9e", "53908bde20f70186a0dc7ab9", "53908e0020f70186a0dd49e6", "5390b36120f70186a0ef23fa"], "authors": ["Supriya Garg", "Tamara Berg", "Klaus Mueller"], "_id": {"$oid": "5797a7e7c60b4bee2de84d79"}}, {"index": "5390b19020f70186a0edff88", "title": "Magic marker: a color analytics interface for image annotation", "abstract": "This paper presents a system that helps users by suggesting appropriate colors for inserting text and symbols into an image. The color distribution in the image regions surrounding the annotation area determines the colors that make a good choice - i.e. capture a viewer's attention, while remaining legible. Each point in the color-space is assigned a distance-map value, where colors with higher values are better choices. This tool works like a \"Magic Marker\" giving users the power to automatically choose a good annotation color, which can be varied based on their personal preferences.", "year": "2011", "venue": "ISVC'11 Proceedings of the 7th international conference on Advances in visual computing - Volume Part I", "citations": [], "references": ["539099a220f70186a0e17e90", "5390a06e20f70186a0e4bb8a", "5390a1e620f70186a0e59878", "5390a28020f70186a0e62b92", "5390879920f70186a0d4188f", "539089ab20f70186a0d96a9c", "53908bcc20f70186a0dc6cd6", "53908cde20f70186a0dce969", "539096cb20f70186a0df6aa0", "5390b95520f70186a0f2f712"], "authors": ["Supriya Garg", "Kshitij Padalkar", "Klaus Mueller"], "_id": {"$oid": "5797a81ec60b4bee2deb2e3b"}}, {"index": "5390b86b20f70186a0f29df8", "title": "Exploratory visual analytics in high dimensional space", "abstract": "Effective decision making in the presence of multivariate data and relationships requires a conceptual high-level understanding of the data as well as tradeoffs to be iteratively evaluated, with the optimal solution slowly emerging over time. To obtain intuitive insights during the data analysis, interactive visualization plays a big role in the science of visual analytics. By augmenting analytics with an interactive visual interface, users can explore their datasets more intuitively in the decision making process. We mainly use cluster analysis techniques for the data analysis. Cluster analysis is an excellent method to understand a dataset without the presence of any prior models or hypotheses and its result can give way to such models. Unlike traditional cluster analysis techniques, we provide several kinds of interactive visual interfaces to allow users to monitor every step of the clustering process. By letting them refine intermediate results, they can provide their intuition or domain knowledge in the process. The analysis can be done not only for a raw dataset but also for feature vectors derived from this raw dataset. This visual analytics process put forward in this work follows an iterative strategy: (1) explore the data using a visual interface, (2) discover some insights, (3) form a high-level model, and (4) refine those models. Due to the often very high-dimensional data in this process, the greatest challenge is the navigation and orientation in the high-dimensional space. Furthermore, due to the exploratory nature of visual analytics, analysts often do not even know their clear preferences until an optimal solution emerges at some point. This solution discovery often involves trade-offs, which are made on the fly in the high-dimensional data exploration process. To facilitate this interactive user-driven optimization process, we have developed an autonomous high-dimensional navigation interface augmented with intuitive navigation aids which allow users to fluently control views onto the data, utilizing illustrative techniques to explore high-dimensional neighborhoods in an insightful manner.", "year": "2011", "venue": "Exploratory visual analytics in high dimensional space", "citations": [], "references": [], "authors": ["Klaus Mueller", "Eun Ju Nam"], "_id": {"$oid": "5797a88cc60b4bee2df0f491"}}, {"index": "558fe3a9612c29c89cd7bea3", "title": "Human Computation in Visualization: Using Purpose Driven Games for Robust Evaluation of Visualization Algorithms", "abstract": "Due to the inherent characteristics of the visualization process, most of the problems in this field have strong ties with human cognition and perception. This makes the human brain and sensory system the only truly appropriate evaluation platform for evaluating and fine-tuning a new visualization method or paradigm. However, getting humans to volunteer for these purposes has always been a significant obstacle, and thus this phase of the development process has traditionally formed a bottleneck, slowing down progress in visualization research. We propose to take advantage of the newly emerging field of Human Computation (HC) to overcome these challenges. HC promotes the idea that rather than considering humans as users of the computational system, they can be made part of a hybrid computational loop consisting of traditional computation resources and the human brain and sensory system. This approach is particularly successful in cases where part of the computational problem is considered intractable using known computer algorithms but is trivial to common sense human knowledge. In this paper, we focus on HC from the perspective of solving visualization problems and also outline a framework by which humans can be easily seduced to volunteer their HC resources. We introduce a purpose-driven game titled \u201cDisguise\u201d which serves as a prototypical example for how the evaluation of visualization algorithms can be mapped into a fun and addicting activity, allowing this task to be accomplished in an extensive yet cost effective way. Finally, we sketch out a framework that transcends from the pure evaluation of existing visualization methods to the design of a new one.", "year": "2012", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": [], "references": [], "authors": ["Nafees Ahmed", "Ziyi Zheng", "Klaus Mueller"], "_id": {"$oid": "5797a68cc60b4bee2dd8bef0"}}, {"index": "5390b7fe20f70186a0f2635b", "title": "Conformal Magnifier: A Focus+Context Technique with Local Shape Preservation", "abstract": "We present the conformal magnifier, a novel interactive focus+context visualization technique that magnifies a region of interest (ROI) using conformal mapping. Our framework supports the arbitrary shape design of magnifiers for the user to enlarge the ROI while globally deforming the context region without any cropping. By using the mathematically well-defined conformal mapping theory and algorithm, the ROI is magnified with local shape preservation (angle distortion minimization), while the transition area between the focus and context regions is deformed smoothly and continuously. After the selection of a specified magnifier shape, our system can automatically magnify the ROI in real time with full resolution even for large volumetric data sets. These properties are important for many visualization applications, especially for the computer aided detection and diagnosis (CAD). Our framework is suitable for diverse applications, including the map visualization, and volumetric visualization. Experimental results demonstrate the effectiveness, robustness, and efficiency of our framework.", "year": "2012", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["5390b7fe20f70186a0f26ba4"], "references": [], "authors": ["Xin Zhao", "Wei Zeng", "David Gu", "Arie Kaufman", "Wei Xu", "Klaus Mueller"], "_id": {"$oid": "5797a704c60b4bee2dde31a1"}}, {"index": "558fdcd2612c29c89cd7ba08", "title": "A Data-Driven Approach to Hue-Preserving Color-Blending", "abstract": "Color mapping and semitransparent layering play an important role in many visualization scenarios, such as information visualization and volume rendering. The combination of color and transparency is still dominated by standard alpha-compositing using the Porter-Duff over operator which can result in false colors with deceiving impact on the visualization. Other more advanced methods have also been proposed, but the problem is still far from being solved. Here we present an alternative to these existing methods specifically devised to avoid false colors and preserve visual depth ordering. Our approach is data driven and follows the recently formulated knowledge-assisted visualization (KAV) paradigm. Preference data, that have been gathered in web-based user surveys, are used to train a support-vector machine model for automatically predicting an optimized hue-preserving blending. We have applied the resulting model to both volume rendering and a specific information visualization technique, illustrative parallel coordinate plots. Comparative renderings show a significant improvement over previous approaches in the sense that false colors are completely removed and important properties such as depth ordering and blending vividness are better preserved. Due to the generality of the defined data-driven blending operator, it can be easily integrated also into other visualization frameworks.", "year": "2012", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["554a4a4e0cf2c69e964873bf"], "references": [], "authors": ["Lars Kuhne", "Joachim Giesen", "Zhiyuan Zhang", "Sungsoo Ha", "Klaus Mueller"], "_id": {"$oid": "5797a720c60b4bee2ddf6b7b"}}, {"index": "5390bd1520f70186a0f44eb1", "title": "Efficient reconstruction and visualization of ct data", "abstract": "Cone-beam CT (Computed Tomography) has become a major imaging technique thanks to its image-fidelity and scanning time. Scientists and practitioners frequently utilize volume visualization tools for diagnosis and decision-making. The thesis work presented here seeks to improve on the volume visualization pipeline for CT generated data. We summarize our contributions into three categories. Cone-beam CT scanners typically use analytical algorithms to reconstruct volumetric data. We studied the interpolation error of visualization tools and built a verifiable visualization tool and efficient data structure to enable users to enjoy interactive rendering speed to freely examine the high resolution data at minimal error. For the recently developed low-dose CT which suffers from either noisy or an insufficient number of X-ray projections, we proposed an optimization framework to determine effective parameters for the data denoising and volume reconstruction stage. We have devised an efficient method to optimize various parameters for iterative CT reconstruction using an ant colony optimization algorithm. We also developed an interactive user interface to visually explore various acquisition settings. Our preliminary results show that the learned parameters can be readily applied to similar scans with promising results. Lastly, we provide visual guidance which can boost user efficiency when exploring the data. For guided visualization, we propose a view suggestion framework rooted in high-dimensional feature space which does not rely on particular transfer functions or volume segmentations as an initial input.", "year": "2012", "venue": "Efficient reconstruction and visualization of ct data", "citations": [], "references": [], "authors": ["Klaus Mueller", "Xianfeng Gu", "Ziyi Zheng"], "_id": {"$oid": "5797a726c60b4bee2ddfac94"}}, {"index": "5390b63320f70186a0f17bfb", "title": "A network-based interface for the exploration of high-dimensional data spaces", "abstract": "The navigation of high-dimensional data spaces remains challenging, making multivariate data exploration difficult. To be effective and appealing for mainstream application, navigation should use paradigms and metaphors that users are already familiar with. One such intuitive navigation paradigm is interactive route planning on a connected network. We have employed such an interface and have paired it with a prominent high-dimensional visualization paradigm showing the N-D data in undistorted raw form: parallel coordinates. In our network interface, the dimensions form nodes that are connected by a network of edges representing the strength of association between dimensions. A user then interactively specifies nodes/edges to visit, and the system computes an optimal route, which can be further edited and manipulated. In our interface, this route is captured by a parallel coordinate data display in which the dimension ordering is configured by the specified route. Our framework serves both as a data exploration environment and as an interactive presentation platform to demonstrate, explain, and justify any identified relationships to others. We demonstrate our interface within a business scenario and other applications.", "year": "2012", "venue": "PACIFICVIS '12 Proceedings of the 2012 IEEE Pacific Visualization Symposium", "citations": [], "references": [], "authors": ["Zhiyuan Zhang", "Kevin T. McDonnell", "Klaus Mueller"], "_id": {"$oid": "5797a751c60b4bee2de1be39"}}, {"index": "558fef81612c29c89cd7c5f6", "title": "Message from the Paper Chairs and Guest Editors", "abstract": "This special issue includes papers that were presented at the IEEE Scientific Visualization Conference 2012 (SciVis 2012) and the IEEE Information Visualization Conference 2012 (InfoVis 2012), held together at IEEE VisWeek from 14-19 October 2012 in Seattle, WA.", "year": "2012", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": [], "references": [], "authors": ["Jason Dykes", "David Laidlaw", "Klaus Mueller", "Giuseppe Santucci", "Gerik Scheuermann", "Matthew Ward", "Chris Weaver"], "_id": {"$oid": "5797a805c60b4bee2de9ee2e"}}, {"index": "5390bd1520f70186a0f44b87", "title": "Improving cancer detection through visualization", "abstract": "The proliferation of medical scanning technology, especially computed tomography (CT) and magnetic resonance imaging (MRI), has led to various research works on methods of intuitively visualizing the large amounts of resulting slice data. The visualization of this data consists not only of display methods, but ideas covering topics such as navigation, exploration, surface parameterization, and analysis. These imaging modalities can play a large role in diagnosing a multitude of diseases, including carcinomas of the colon, lungs, and prostate. The work presented in this dissertation develops varied visualization techniques for application to the detection and localization of these three prevalent cancers. All techniques presented herein were developed and tested using real patient data acquired from CT or MRI scanning modalities. There has been substantial research performed in the development of clinical virtual colonoscopy (VC) systems based on CT scans, but methods to meld multiple sources of diagnostic information are still under active development. Presented are beginning methods to merge VC with the traditional optical colonoscopy, such that VC information can be better utilized on a patient referred for the optical procedure. This work includes a method for removing the radial distortion introduced by the fisheye lens on the endoscope and a method for correlating the path of the physical colonoscope with the VC path. Techniques are also presented here which can enhance a traditional VC environment. For CT scans of the colon acquired with the patient in different orientations, a method is presented to register the two scans together in a one-to-one and onto manner. This direct mapping between the two surfaces allows for the corresponding visualization of the same location within each of the two colon models. Mesh models are often used as a map to show the user's location within an object. In the case of VC, this 3D model can often have occlusions due to the twisted shape of the colon. A method is presented to create a planar map which preserves the global shape of the colon and does not contain any overlapping sections. This allows for the user to observe the entire colon surface at once, ensuring that there are no occlusions which could lead to an ambiguity in determining one's location. Similar problems exist for exploring the lungs in virtual bronchoscopy applications, and can be even worse, due to the large number of bifurcations. The idea of a context preserving map is expanded from tubular structures to treelike structures, being applicable not only to the bronchi, but other branching structures such as blood vessels. As there are different aspects to be addressed compared to a simple tubular structure, this work is not simply an extension, but presents new methods which have been developed to deal with the challenges inherent in treelike structures. For the prostate, multiple MRI modes are typically used for the detection of cancer. Compared to colon and lung cancer, the prostate has so far seen relatively little in terms of visualization research, and work is presented here on how to combine the multiple MR modes to assist in the detection of prostate cancer. This includes an upsampling and analysis of the slices to identify regions of interest and the display of these regions within the prostate along with the surrounding anatomy using multi-volume rendering. Also developed is a method of visibility persistence to allow for easy viewing of occluded regions of interest, the ability of the user to paint custom regions into the data, and an extension of the visibility persistence to these user painted regions.", "year": "2012", "venue": "Improving cancer detection through visualization", "citations": [], "references": [], "authors": ["Arie Kaufman", "Klaus Mueller", "Joseph Marino"], "_id": {"$oid": "5797a844c60b4bee2ded2576"}}, {"index": "5390be6620f70186a0f4bbfc", "title": "SketchPadN-D: WYDIWYG Sculpting and Editing in High-Dimensional Space", "abstract": "High-dimensional data visualization has been attracting much attention. To fully test related software and algorithms, researchers require a diverse pool of data with known and desired features. Test data do not always provide this, or only partially. Here we propose the paradigm WYDIWYGS (What You Draw Is What You Get). Its embodiment, SketchPadND, is a tool that allows users to generate high-dimensional data in the same interface they also use for visualization. This provides for an immersive and direct data generation activity, and furthermore it also enables users to interactively edit and clean existing high-dimensional data from possible artifacts. SketchPadND offers two visualization paradigms, one based on parallel coordinates and the other based on a relatively new framework using an N-D polygon to navigate in high-dimensional space. The first interface allows users to draw arbitrary profiles of probability density functions along each dimension axis and sketch shapes for data density and connections between adjacent dimensions. The second interface embraces the idea of sculpting. Users can carve data at arbitrary orientations and refine them wherever necessary. This guarantees that the data generated is truly high-dimensional. We demonstrate our tool's usefulness in real data visualization scenarios.", "year": "2013", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": [], "references": [], "authors": ["Bing Wang", "Puripant Ruchikachorn", "Klaus Mueller"], "_id": {"$oid": "5797a6a8c60b4bee2dda3012"}}, {"index": "5390be6620f70186a0f4bb8e", "title": "The Five Ws for Information Visualization with Application to Healthcare Informatics", "abstract": "The Five Ws is a popular concept for information gathering in journalistic reporting. It captures all aspects of a story or incidence: who, when, what, where, and why. We propose a framework composed of a suite of cooperating visual information displays to represent the Five Ws and demonstrate its use within a healthcare informatics application. Here, the who is the patient, the where is the patient's body, and the when, what, why is a reasoning chain which can be interactively sorted and brushed. The patient is represented as a radial sunburst visualization integrated with a stylized body map. This display captures all health conditions of the past and present to serve as a quick overview to the interrogating physician. The reasoning chain is represented as a multistage flow chart, composed of date, symptom, data, diagnosis, treatment, and outcome. Our system seeks to improve the usability of information captured in the electronic medical record (EMR) and we show via multiple examples that our framework can significantly lower the time and effort needed to access the medical patient information required to arrive at a diagnostic conclusion.", "year": "2013", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": [], "references": [], "authors": ["Zhiyuan Zhang", "Bing Wang", "Faisal Ahmed", "Iv Ramakrishnan", "Rong Zhao", "Asa Viccellio", "Klaus Mueller"], "_id": {"$oid": "5797a6aec60b4bee2dda83c4"}}, {"index": "5390baa120f70186a0f38527", "title": "WhereAmI: image-based positioning in dense urban areas", "abstract": "", "year": "2013", "venue": "Proceeding of the 11th annual international conference on Mobile systems, applications, and services", "citations": [], "references": ["5390a45620f70186a0e735d4"], "authors": ["Quoc Duy Vo", "Klaus Mueller", "Pradipta De"], "_id": {"$oid": "5797a712c60b4bee2ddece96"}}, {"index": "5390c04520f70186a0f562bb", "title": "Using GPUs to Crack Android Pattern-Based Passwords", "abstract": "We investigate the strength of patterns as secret signatures in Android's pattern based authentication mechanism. Parallelism of GPU is exploited to exhaustively search for the secret pattern. Typically, searching for a pattern, composed of a number of nodes and edges, requires an exhaustive search for the pattern. In this work, we show that the use of GPU can speed up the graph search, hence the pattern password, through parallelization. Preliminary results on cracking the Android pattern based passwords shows that the technique can be used as the basis to implement a tool that can check the strength of a pattern based password and thereby recommend strong patterns to the user.", "year": "2013", "venue": "ICPADS '13 Proceedings of the 2013 International Conference on Parallel and Distributed Systems", "citations": [], "references": [], "authors": ["Jaewoo Pi", "Pradipta De", "Klaus Mueller"], "_id": {"$oid": "5797a829c60b4bee2debc608"}}, {"index": "5390b95520f70186a0f2f461", "title": "TripAdvisor^{N-D}: A Tourism-Inspired High-Dimensional Space Exploration Framework with Overview and Detail", "abstract": "Gaining a true appreciation of high-dimensional space remains difficult since all of the existing high-dimensional space exploration techniques serialize the space travel in some way. This is not so foreign to us since we, when traveling, also experience the world in a serial fashion. But we typically have access to a map to help with positioning, orientation, navigation, and trip planning. Here, we propose a multivariate data exploration tool that compares high-dimensional space navigation with a sightseeing trip. It decomposes this activity into five major tasks: 1) Identify the sights: use a map to identify the sights of interest and their location; 2) Plan the trip: connect the sights of interest along a specifyable path; 3) Go on the trip: travel along the route; 4) Hop off the bus: experience the location, look around, zoom into detail; and 5) Orient and localize: regain bearings in the map. We describe intuitive and interactive tools for all of these tasks, both global navigation within the map and local exploration of the data distributions. For the latter, we describe a polygonal touchpad interface which enables users to smoothly tilt the projection plane in high-dimensional space to produce multivariate scatterplots that best convey the data relationships under investigation. Motion parallax and illustrative motion trails aid in the perception of these transient patterns. We describe the use of our system within two applications: 1) the exploratory discovery of data configurations that best fit a personal preference in the presence of tradeoffs and 2) interactive cluster analysis via cluster sculpting in N-D.", "year": "2013", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["558b7840612c6b62e5e893f9"], "references": [], "authors": ["Julia EunJu Nam", "Klaus Mueller"], "_id": {"$oid": "5797a8bfc60b4bee2df39bb6"}}, {"index": "5390bf1320f70186a0f502db", "title": "A Structure-Based Distance Metric for High-Dimensional Space Exploration with Multidimensional Scaling", "abstract": "Although the euclidean distance does well in measuring data distances within high-dimensional clusters, it does poorly when it comes to gauging intercluster distances. This significantly impacts the quality of global, low-dimensional space embedding procedures such as the popular multidimensional scaling (MDS) where one can often observe nonintuitive layouts. We were inspired by the perceptual processes evoked in the method of parallel coordinates which enables users to visually aggregate the data by the patterns the polylines exhibit across the dimension axes. We call the path of such a polyline its structure and suggest a metric that captures this structure directly in high-dimensional space. This allows us to better gauge the distances of spatially distant data constellations and so achieve data aggregations in MDS plots that are more cognizant of existing high-dimensional structure similarities. Our biscale framework distinguishes far-distances from near-distances. The coarser scale uses the structural similarity metric to separate data aggregates obtained by prior classification or clustering, while the finer scale employs the appropriate euclidean distance.", "year": "2014", "venue": "IEEE Transactions on Visualization and Computer Graphics", "citations": ["558af7e3612c41e6b9d3ef5a"], "references": [], "authors": ["Jenny Hyunjung Lee", "Kevin T. McDonnell", "Alla Zelenyuk", "Dan Imre", "Klaus Mueller"], "_id": {"$oid": "5797a708c60b4bee2dde6012"}}, {"index": "558b1b48612c41e6b9d43757", "title": "Gamification as a paradigm for the evaluation of visual analytics systems", "abstract": "The widespread web-based connectivity of people all over the world has yielded new opportunities to recruit humans for visual analytics evaluation and for an abundance of other tasks. Known as crowdsourcing, humans typically receive monetary incentives to participate. However, while these payments are small per evaluation, the cost can add up for realistically-sized studies. Furthermore, since the reward is money, the quality of the evaluation can suffer. Our approach uses radically different incentives, namely entertainment, pleasure, and the feeling of success. We propose a theory, methodology and framework that can allow any visual analytics researcher to turn his/her evaluation task into an entertaining online game. First experiences with a prototype have shown that such an approach allows ten-thousands of evaluations to be done in a matter of days at no cost which is completely unthinkable with conventional methods.", "year": "2014", "venue": "Proceedings of the Fifth Workshop on Beyond Time and Errors: Novel Evaluation Methods for Visualization", "citations": [], "references": ["5390979920f70186a0e010cd", "5390aca920f70186a0eb93d8", "5390aca920f70186a0eb93da", "5390be6620f70186a0f4bbbd", "5390a7f620f70186a0e94e7b", "5390a1d420f70186a0e56d20", "539098b820f70186a0e0a1d7", "5390baa120f70186a0f38663", "5390a6d920f70186a0e87dde", "5390a6d920f70186a0e87ddd", "5390ada620f70186a0ec24b3", "5390afc920f70186a0ed2295", "5390a93b20f70186a0ea0a8b", "539099ec20f70186a0e1d6a4", "5390ba0a20f70186a0f33a42", "5390b00c20f70186a0ed44f8", "5390b5c620f70186a0f08af2", "5390a93b20f70186a0ea098f", "5390afc920f70186a0ed2254", "5390ad0620f70186a0eba105", "5390a06e20f70186a0e4cada", "5390a01420f70186a0e482c1", "5390b2fc20f70186a0eedd8a", "5390afc920f70186a0ed24ab", "5390b72e20f70186a0f227a0", "5390b1d220f70186a0ee109a", "5390a5dc20f70186a0e7f015", "5390b19020f70186a0ee065a", "5390a6d920f70186a0e87da8", "539096cb20f70186a0df7db8", "53908bad20f70186a0dc315c", "5390b44620f70186a0efa427", "5390aefc20f70186a0ecd8e0", "539099ec20f70186a0e1d6b1", "539096cb20f70186a0df711e", "5390995c20f70186a0e14132", "5390995c20f70186a0e14131", "5390995c20f70186a0e1412f", "5390a28020f70186a0e62b92", "5390958a20f70186a0def678", "5390b52620f70186a0f033d7", "5390be6620f70186a0f4bbaf", "539087e720f70186a0d69090"], "authors": ["Nafees Ahmed", "Klaus Mueller"], "_id": {"$oid": "5797a791c60b4bee2de4d84f"}}, {"index": "558b7840612c6b62e5e893f9", "title": "TorusVisND: unraveling high-dimensional torus networks for network traffic visualizations", "abstract": "Torus networks are widely used in supercomputing. However, due to their complex topology and their large number of nodes, it is difficult for analysts to perceive the messages flow in these networks. We propose a visualization framework called TorusVisND that uses modern information visualization techniques to allow analysts to see the network and its communication patterns in a single display and control the amount of information shown via filtering in the temporal and the topology domains. For this purpose we provide three cooperating visual interfaces. The main interface is the network display. It uses two alternate graph numbering schemes -- a sequential curve and a Hilbert curve -- to unravel the 5D torus network into a single string of nodes. We then arrange these nodes onto a circle and add the communication links as line bundles in the circle interior. A node selector based on parallel coordinates and a time slicer based on ThemeRiver help users focus on certain processor groups and time slices in the network display. We demonstrate our approach via a small use case.", "year": "2014", "venue": "Proceedings of the First Workshop on Visual Performance Analysis", "citations": [], "references": ["53909f2c20f70186a0e37799", "5390a5b020f70186a0e7d62e", "53908cde20f70186a0dcd89e", "539087e620f70186a0d6759b", "5390b95520f70186a0f2f78e", "5390958a20f70186a0def693", "5390bae520f70186a0f3ada5", "539089d320f70186a0d9c2ba", "5390877920f70186a0d2efee", "5390b95520f70186a0f2f461", "539087cf20f70186a0d5c1be", "53908bcc20f70186a0dc6e1b"], "authors": ["Shenghui Cheng", "Pradipta De", "Shaofeng H.-C. Jiang", "Klaus Mueller"], "_id": {"$oid": "5797a8b5c60b4bee2df3196f"}}]